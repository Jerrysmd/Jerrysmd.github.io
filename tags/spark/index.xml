<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on JerrysBlog</title>
    <link>https://Jerrysmd.github.io/tags/spark/</link>
    <description>Recent content in spark on JerrysBlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 11 Aug 2020 10:42:19 +0800</lastBuildDate><atom:link href="https://Jerrysmd.github.io/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark On Yarn: yarn-cluster, yarn-client</title>
      <link>https://Jerrysmd.github.io/post/20200811yarn-clusteryarn-client/yarn-clusteryarn-client/</link>
      <pubDate>Tue, 11 Aug 2020 10:42:19 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20200811yarn-clusteryarn-client/yarn-clusteryarn-client/</guid>
      <description>
        
          
            &lt;p&gt;Spark can run on YARN, but Spark on YARN has two modes: yarn-cluster and yarn-client.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Spark 简介: Spark Guide, Part Ⅲ</title>
      <link>https://Jerrysmd.github.io/post/20200803sparkguide3/sparkguide3/</link>
      <pubDate>Mon, 03 Aug 2020 16:10:33 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20200803sparkguide3/sparkguide3/</guid>
      <description>
        
          
            &lt;p&gt;Apache Spark has its architectural foundation in the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. The Dataframe API was released as an abstraction on top of the RDD, followed by the Dataset API.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Spark 简介: Spark Guide, Part Ⅱ</title>
      <link>https://Jerrysmd.github.io/post/20200707sparkguide2/sparkguide2/</link>
      <pubDate>Tue, 07 Jul 2020 11:14:54 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20200707sparkguide2/sparkguide2/</guid>
      <description>
        
          
            &lt;p&gt;Apache Spark has its architectural foundation in the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. The Dataframe API was released as an abstraction on top of the RDD, followed by the Dataset API.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Spark 简介: Spark Guide, Part Ⅰ</title>
      <link>https://Jerrysmd.github.io/post/20200527sparkguide1/sparkguide1/</link>
      <pubDate>Wed, 27 May 2020 17:20:52 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20200527sparkguide1/sparkguide1/</guid>
      <description>
        
          
            &lt;p&gt;Apache Spark has its architectural foundation in the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. The Dataframe API was released as an abstraction on top of the RDD, followed by the Dataset API.&lt;/p&gt;
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
