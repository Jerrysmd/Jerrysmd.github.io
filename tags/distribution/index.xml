<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>distribution on JerrysBlog</title>
    <link>https://Jerrysmd.github.io/tags/distribution/</link>
    <description>Recent content in distribution on JerrysBlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 07 Jul 2021 11:14:54 +0800</lastBuildDate><atom:link href="https://Jerrysmd.github.io/tags/distribution/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark 简介: Spark Guide, Part Ⅲ</title>
      <link>https://Jerrysmd.github.io/post/20210707sparkguide3/sparkguide3/</link>
      <pubDate>Wed, 07 Jul 2021 11:14:54 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210707sparkguide3/sparkguide3/</guid>
      <description>
        
          &lt;p&gt;Apache Spark has its architectural foundation in the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. The Dataframe API was released as an abstraction on top of the RDD, followed by the Dataset API.&lt;/p&gt;
&lt;h2 id=&#34;advanced-operation&#34;&gt;Advanced Operation&lt;/h2&gt;
&lt;h3 id=&#34;closure&#34;&gt;closure&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;closure&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;closure&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Double&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;factor&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;3.14&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;areaFunction&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;        &lt;span class=&#34;n&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pow&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;factor&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;areaFunction&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;f就是闭包，闭包的本质就是一个函数&lt;/li&gt;
&lt;li&gt;在scala中函数是一个特殊的类型，FunctionX&lt;/li&gt;
&lt;li&gt;闭包也是一个FunctionX类型的对象&lt;/li&gt;
&lt;li&gt;闭包是一个对象&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;MyClass&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;field&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Hello&amp;#34;&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;doStuff&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rdd&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;RDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;RDD&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;        &lt;span class=&#34;n&#34;&gt;rdd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;field&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;//引用Myclass对象中的一个成员变量，说明其可以访问MyClass这个类的总用域，也是一个闭包。封闭的是MyClass这个作用域。
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;//在将其分发的不同的Executor中执行的时候，其依赖MyClass这个类当前的对象，因为其封闭了这个作用域。MyClass和函数都要一起被序列化。发到不同的结点中执行。
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;//1. 如果MyClass不能被序列化，将会报错
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;//2. 如果在这个闭包中，依赖了一个外部很大的集合，那么这个集合会随着每一个Task分发
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;global-accumulator&#34;&gt;Global accumulator&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在任意地方创建long accumulator&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;累加&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;longAccumulator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;counter&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;broadcast&#34;&gt;Broadcast&lt;/h3&gt;
&lt;p&gt;广播变量允许将一个Read-Only的变量缓存到集群中的每个节点上，而不是传递给每一个Task一个副本&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集群中的每个节点指的是一个机器&lt;/li&gt;
&lt;li&gt;每一个Task，一个Task是一个Stage中的最小处理单元，一个Executor中可以有多个Stage，每个Stage有多个Task&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以在需要多个Stage的多个Task中使用相同数据的情况下，广播特别有用&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Spark&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;http[123]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;scala&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;http[456]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;config&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkConf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setMaster&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;local[6]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setAppName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;bc&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//创建广播
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;broadcast&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Spark&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Scala&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//使用广播变量代替直接引用集合，只会复制和executor一样的数量
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//在使用广播之前，复制map了task数量份
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//在使用广播之后，复制次数和executor数量一致
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;sparksql&#34;&gt;SparkSQL&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Spark的RDD主要用于处理非结构化数据和半结构化数据&lt;/li&gt;
&lt;li&gt;SparkSQL主要用于处理结构化数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;虽然SparkSQL是基于RDD的，但是SparkSQL的速度比RDD要快很多&lt;/li&gt;
&lt;li&gt;SparkSQL提供了更好的外部数据源读写支持&lt;/li&gt;
&lt;li&gt;SparkSQL提供了直接访问列的能力&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;SparkSession&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;SparkSession&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Builder&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;	&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;appName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;hello&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;	&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;master&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;local[6]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;	&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getOrCreate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;impart&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;implicits&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;personRDD&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;RDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;people&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sparkContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;zs&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;ls&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;personDS&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;PersonRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toDS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;teenagers&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;PersonDS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&amp;#39;age &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;	&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&amp;#39;age &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;	&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&amp;#39;name&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;	&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;RDD和SparkSQL运行时的区别&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;RDD的运行流程：&lt;/p&gt;
&lt;p&gt;RDD-&amp;gt;DAGScheduler-&amp;gt;TaskScheduleri-&amp;gt;Worker&lt;/p&gt;
&lt;p&gt;先将RDD解析为由Stage组成的DAG，后将Stage转为Task直接运行&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SparkSQL的运行流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;解析SQL，并且生成AST（抽象语法树）&lt;/li&gt;
&lt;li&gt;在AST中加入元数据信息，做这一步主要是为了一些优化，例如 col = col 这样的条件&lt;/li&gt;
&lt;li&gt;对已经加入元数据的AST，输入优化器，进行优化（例如：谓词下推，列值裁剪）&lt;/li&gt;
&lt;li&gt;生成的AST其实最终还没办法直接运行，这个AST是逻辑计划，结束后，需要生成物理计划，从而生成RDD来运行。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;dataset--dataframe&#34;&gt;Dataset &amp;amp; DataFrame&lt;/h2&gt;
        
      </description>
    </item>
    
    <item>
      <title>Hive 重点: Hive Key Points</title>
      <link>https://Jerrysmd.github.io/post/20210615hivekeypoint/hivekeypoint/</link>
      <pubDate>Tue, 15 Jun 2021 09:26:00 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210615hivekeypoint/hivekeypoint/</guid>
      <description>
        
          &lt;p&gt;Hive is a Hadoop-based data warehouse tool that maps structured data files into a database table and provides complete SQL query functionality that converts SQL statements into MapReduce tasks for execution. It is very suitable for statistical analysis of data warehouse.&lt;/p&gt;
&lt;h2 id=&#34;hive的两张表关联使用mapreduce怎么实现&#34;&gt;Hive的两张表关联，使用MapReduce怎么实现？&lt;/h2&gt;
&lt;p&gt;如果其中有一张表为小表，直接使用map端join的方式（map端加载小表）进行聚合。&lt;/p&gt;
&lt;p&gt;如果两张都是大表，那么采用联合key，联合key的第一个组成部分是joinon中的公共字段，第二部分是一个flag，0代表表A，1代表表B，由此让Reduce区分客户信息和订单信息；在Mapper中同时处理两张表的信息，将joinon公共字段相同的数据划分到同一个分区中，进而传递到一个Reduce中，然后在Reduce中实现聚合。&lt;/p&gt;
&lt;h2 id=&#34;hive的特点hive和rdbms有什么异同&#34;&gt;Hive的特点，Hive和RDBMS有什么异同？&lt;/h2&gt;
&lt;p&gt;hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析，但是Hive不支持实时查询。&lt;/p&gt;
&lt;p&gt;Hive与关系型数据库的区别：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210615hiveKeyPoint/hqlDifferents.png&#34; alt=&#34;hqlDifferents&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;hive中sortbyorderbyclusterbydistrbuteby各代表什么意思&#34;&gt;hive中SortBy，OrderBy，ClusterBy，DistrbuteBy各代表什么意思？&lt;/h2&gt;
&lt;p&gt;Orderby：会对输入做全局排序，因此只有一个reducer（多个reducer无法保证全局有序）。只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。&lt;/p&gt;
&lt;p&gt;Sortby：不是全局排序，其在数据进入reducer前完成排序。&lt;/p&gt;
&lt;p&gt;Distributeby：按照指定的字段对数据进行划分输出到不同的reduce中。&lt;/p&gt;
&lt;p&gt;Clusterby：除了具有distributeby的功能外还兼具sortby的功能。&lt;/p&gt;
&lt;h2 id=&#34;hive中splitcoalesce及collect_list函数的用法举例&#34;&gt;Hive中split、coalesce及collect_list函数的用法（举例）？&lt;/h2&gt;
&lt;p&gt;split将字符串转化为数组，即：split(&#39;a,b,c,d&#39;,&#39;,&#39;)==&amp;gt;[&amp;quot;a&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;d&amp;quot;]。&lt;/p&gt;
&lt;p&gt;coalesce(Tv1,Tv2,…)返回参数中的第一个非空值；如果所有值都为NULL，那么返回NULL。&lt;/p&gt;
&lt;p&gt;collect_list列出该字段所有的值，不去重=&amp;gt;selectcollect_list(id)fromtable。&lt;/p&gt;
&lt;h2 id=&#34;hive有哪些方式保存元数据各有哪些特点&#34;&gt;Hive有哪些方式保存元数据，各有哪些特点？&lt;/h2&gt;
&lt;p&gt;Hive支持三种不同的元存储服务器，分别为：内嵌式元存储服务器、本地元存储服务器、远程元存储服务器，每种存储方式使用不同的配置参数。&lt;/p&gt;
&lt;p&gt;内嵌式元存储主要用于单元测试，在该模式下每次只有一个进程可以连接到元存储，Derby是内嵌式元存储的默认数据库。&lt;/p&gt;
&lt;p&gt;在本地模式下，每个Hive客户端都会打开到数据存储的连接并在该连接上请求SQL查询。&lt;/p&gt;
&lt;p&gt;在远程模式下，所有的Hive客户端都将打开一个到元数据服务器的连接，该服务器依次查询元数据，元数据服务器和客户端之间使用Thrift协议通信。&lt;/p&gt;
&lt;h2 id=&#34;hive内部表和外部表的区别&#34;&gt;Hive内部表和外部表的区别？&lt;/h2&gt;
&lt;p&gt;创建表时：创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。&lt;/p&gt;
&lt;p&gt;删除表时：在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。&lt;/p&gt;
&lt;h2 id=&#34;hive的函数udfudafudtf的区别&#34;&gt;Hive的函数：UDF、UDAF、UDTF的区别？&lt;/h2&gt;
&lt;p&gt;UDF：单行进入，单行输出&lt;/p&gt;
&lt;p&gt;UDAF：多行进入，单行输出&lt;/p&gt;
&lt;p&gt;UDTF：单行输入，多行输出&lt;/p&gt;
&lt;h2 id=&#34;所有的hive任务都会有mapreduce的执行吗&#34;&gt;所有的Hive任务都会有MapReduce的执行吗？&lt;/h2&gt;
&lt;p&gt;不是，从Hive0.10.0版本开始，对于简单的不需要聚合的类似SELECTfrom&lt;/p&gt;
&lt;p&gt;LIMITn语句，不需要起MapReducejob，直接通过Fetchtask获取数据。&lt;/p&gt;
&lt;h2 id=&#34;hive桶表的理解&#34;&gt;Hive桶表的理解？&lt;/h2&gt;
&lt;p&gt;桶表是对数据&lt;code&gt;某个字段&lt;/code&gt;进行哈希取值，然后放到不同文件中存储。&lt;/p&gt;
&lt;p&gt;数据加载到桶表时，会对字段取hash值，然后与桶的数量取模。把数据放到对应的文件中。物理上，每个桶就是表(或分区）目录里的一个文件，一个作业产生的桶(输出文件)和reduce任务个数相同。&lt;/p&gt;
&lt;p&gt;桶表专门用于抽样查询，是很专业性的，不是日常用来存储数据的表，需要抽样查询时，才创建和使用桶表。&lt;/p&gt;
&lt;h2 id=&#34;hive底层与数据库交互原理&#34;&gt;Hive底层与数据库交互原理？&lt;/h2&gt;
&lt;p&gt;Hive的查询功能是由HDFS和MapReduce结合起来实现的，对于大规模数据查询还是不建议在hive中，因为过大数据量会造成查询十分缓慢。Hive与MySQL的关系：只是借用MySQL来存储hive中的表的元数据信息，称为metastore（元数据信息）。&lt;/p&gt;
&lt;h2 id=&#34;hive本地模式&#34;&gt;Hive本地模式&lt;/h2&gt;
&lt;p&gt;大多数的HadoopJob是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务时消耗可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。&lt;/p&gt;
&lt;p&gt;用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。&lt;/p&gt;
&lt;h2 id=&#34;hive中的压缩格式textfilesequencefilercfileorcfile各有什么区别&#34;&gt;Hive中的压缩格式TextFile、SequenceFile、RCfile、ORCfile各有什么区别？&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1、TextFile&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;默认格式，&lt;strong&gt;存储方式为行存储，数据不做压缩，磁盘开销大，数据解析开销大&lt;/strong&gt;。可结合Gzip、Bzip2使用(系统自动检查，执行查询时自动解压)，但使用这种方式，压缩后的文件不支持split，Hive不会对数据进行切分，从而无法对数据进行并行操作。并且在反序列化过程中，必须逐个字符判断是不是分隔符和行结束符，因此反序列化开销会比SequenceFile高几十倍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、SequenceFile&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SequenceFile是HadoopAPI提供的一种二进制文件支持，&lt;strong&gt;存储方式为行存储，其具有使用方便、可分割、可压缩的特点&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;SequenceFile支持三种压缩选择：&lt;code&gt;NONE&lt;/code&gt;，&lt;code&gt;RECORD&lt;/code&gt;，&lt;code&gt;BLOCK&lt;/code&gt;。Record压缩率低，&lt;strong&gt;一般建议使用BLOCK压缩&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;优势是文件和hadoopapi中的MapFile是相互兼容的&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、RCFile&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;存储方式：&lt;strong&gt;数据按行分块，每块按列存储&lt;/strong&gt;。结合了行存储和列存储的优点：&lt;/p&gt;
&lt;p&gt;首先，RCFile保证同一行的数据位于同一节点，因此元组重构的开销很低；&lt;/p&gt;
&lt;p&gt;其次，像列存储一样，RCFile能够利用列维度的数据压缩，并且能跳过不必要的列读取；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、ORCFile&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;存储方式：数据按行分块每块按照列存储。&lt;/p&gt;
&lt;p&gt;压缩快、快速列存取。&lt;/p&gt;
&lt;p&gt;效率比rcfile高，是rcfile的改良版本。&lt;/p&gt;
&lt;p&gt;小结：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相比TEXTFILE和SEQUENCEFILE，RCFILE由于列式存储方式，数据加载时性能消耗较大，但是具有较好的压缩比和查询响应&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据仓库的特点是一次写入、多次读取，因此，整体来看，RCFILE相比其余两种格式具有较明显的优势&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;hive表关联查询如何解决数据倾斜的问题&#34;&gt;Hive表关联查询，如何解决数据倾斜的问题？&lt;/h2&gt;
&lt;p&gt;1）倾斜原因：map输出数据按keyHash的分配到reduce中，由于key分布不均匀、业务数据本身的特、建表时考虑不周、等原因造成的reduce上的数据量差异过大。
 （1）key分布不均匀;
 （2）业务数据本身的特性;
 （3）建表时考虑不周;
 （4）某些SQL语句本身就有数据倾斜;
 如何避免：对于key为空产生的数据倾斜，可以对其赋予一个随机值。
 2）解决方案
 （1）参数调节：
  hive.map.aggr=true
  hive.groupby.skewindata=true
 有数据倾斜的时候进行负载均衡，当选项设定位true,生成的查询计划会有两个MRJob。第一个MRJob中，Map的输出结果集合会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的GroupByKey有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MRJob再根据预处理的数据结果按照GroupByKey分布到Reduce中（这个过程可以保证相同的GroupByKey被分布到同一个Reduce中），最后完成最终的聚合操作。
 （2）SQL语句调节：
 ①选用joinkey分布最均匀的表作为驱动表。做好列裁剪和filter操作，以达到两表做join的时候，数据量相对变小的效果。
 ②大小表Join：
  使用mapjoin让小的维度表（1000条以下的记录条数）先进内存。在map端完成reduce。
 ③大表Join大表：
  把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后并不影响最终结果。
 ④countdistinct大量相同特殊值:
  countdistinct时，将值为空的情况单独处理，如果是计算countdistinct，可以不用处理，直接过滤，在最后结果中加1。如果还有其他计算，需要进行groupby，可以先将值为空的记录单独处理，再和其他计算结果进行union。&lt;/p&gt;
&lt;h2 id=&#34;fetch抓取&#34;&gt;Fetch抓取&lt;/h2&gt;
&lt;p&gt;Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：SELECT*FROMemployees;在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。&lt;/p&gt;
&lt;p&gt;在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。&lt;/p&gt;
&lt;h2 id=&#34;小表大表join&#34;&gt;小表、大表Join&lt;/h2&gt;
&lt;p&gt;将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用Group让小的维度表（1000条以下的记录条数）先进内存。在map端完成reduce。&lt;/p&gt;
&lt;p&gt;实际测试发现：新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。&lt;/p&gt;
&lt;h2 id=&#34;大表join大表&#34;&gt;大表Join大表&lt;/h2&gt;
&lt;p&gt;1）空KEY过滤 有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。例如key对应的字段为空。2）空key转换 有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。&lt;/p&gt;
&lt;h2 id=&#34;groupby&#34;&gt;GroupBy&lt;/h2&gt;
&lt;p&gt;默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。&lt;/p&gt;
&lt;p&gt;1）开启Map端聚合参数设置  （1）是否在Map端进行聚合，默认为True   hive.map.aggr=true  （2）在Map端进行聚合操作的条目数目   hive.groupby.mapaggr.checkinterval=100000  （3）有数据倾斜的时候进行负载均衡（默认是false）   hive.groupby.skewindata=true&lt;strong&gt;当选项设定为true，生成的查询计划会有两个MRJob&lt;/strong&gt;。第一个MRJob中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是&lt;strong&gt;相同的GroupByKey有可能被分发到不同的Reduce中&lt;/strong&gt;，从而达到负载均衡的目的；第二个MRJob再根据预处理的数据结果按照GroupByKey分布到Reduce中（这个过程可以保证相同的GroupByKey被分布到同一个Reduce中），最后完成最终的聚合操作。&lt;/p&gt;
&lt;h2 id=&#34;countdistinct去重统计&#34;&gt;Count(Distinct)去重统计&lt;/h2&gt;
&lt;p&gt;数据量小的时候无所谓，数据量大的情况下，由于COUNTDISTINCT操作需要用一个ReduceTask来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNTDISTINCT使用先GROUPBY再COUNT的方式替换&lt;/p&gt;
&lt;h2 id=&#34;笛卡尔积&#34;&gt;笛卡尔积&lt;/h2&gt;
&lt;p&gt;尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积&lt;/p&gt;
&lt;h2 id=&#34;行列过滤&#34;&gt;行列过滤&lt;/h2&gt;
&lt;p&gt;列处理：在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT*。&lt;/p&gt;
&lt;p&gt;行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤。&lt;/p&gt;
&lt;h2 id=&#34;并行执行&#34;&gt;并行执行&lt;/h2&gt;
&lt;p&gt;Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。&lt;/p&gt;
&lt;p&gt;通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>Spark 简介: Spark Guide, Part Ⅱ</title>
      <link>https://Jerrysmd.github.io/post/20210527sparkguide2/sparkguide2/</link>
      <pubDate>Thu, 27 May 2021 17:20:52 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210527sparkguide2/sparkguide2/</guid>
      <description>
        
          &lt;p&gt;Apache Spark has its architectural foundation in the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. The Dataframe API was released as an abstraction on top of the RDD, followed by the Dataset API.&lt;/p&gt;
&lt;h2 id=&#34;action-operator&#34;&gt;Action Operator&lt;/h2&gt;
&lt;h3 id=&#34;reducet-t---u&#34;&gt;reduce((T, T) - U)&lt;/h3&gt;
&lt;p&gt;对整个结果集规约，最终生成一条数据，是整个数据集的总汇&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;reduceByKey和reduce有什么区别：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;reduce是action算子，reduceByKey是一个转换算子&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RDD里有一万条数据，大部分key是相同的，有10个不同的key生成10条数据&lt;/p&gt;
&lt;p&gt;reduce生成1条数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reduceByKey是按Key分组，然后把每组聚合&lt;/p&gt;
&lt;p&gt;reduce是针对一整个数据集进行聚合&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reduceByKey是对KV数据进行计算&lt;/p&gt;
&lt;p&gt;reduce可针对所有类型数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;reduce算子是一个shuffle操作吗？&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;shuffle操作分为mapper和reducer，mapper将数据放入paritioner的函数计算，求得往哪个reducer里放&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reduce操作没有mapper和reducer，因为reduce算子会作用于RDD中的每个分区，然后分区求得局部结果，最终汇总到Driver中求得最终结果&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RDD有五大属性，partitioner在shuffle过程中使用&lt;/p&gt;
&lt;p&gt;paritioner只有kv型的RDD才有&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;collect&#34;&gt;collect()&lt;/h3&gt;
&lt;p&gt;以数组的形式返回数据集中所有元素&lt;/p&gt;
&lt;h3 id=&#34;countbykey&#34;&gt;countByKey()&lt;/h3&gt;
&lt;p&gt;count和countByKey&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;countByKey结果：Map(Key -&amp;gt; Key的count)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;调用Action会生成一个job，job会运行获取结果，所以在两个job中有大量的log&lt;/p&gt;
&lt;p&gt;数据倾斜：解决数据倾斜的问题，需要先通过countByKey查看Key对应的数量&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;first&#34;&gt;first()&lt;/h3&gt;
&lt;p&gt;返回第一个元素&lt;/p&gt;
&lt;h3 id=&#34;taken&#34;&gt;take(N)&lt;/h3&gt;
&lt;p&gt;返回前N个元素&lt;/p&gt;
&lt;h3 id=&#34;takesamplewithreplacement-num&#34;&gt;takeSample(withReplacement, num)&lt;/h3&gt;
&lt;p&gt;类似于sample，区别这是action，直接返回结果&lt;/p&gt;
&lt;p&gt;withReplacement：取数据有无放回&lt;/p&gt;
&lt;h3 id=&#34;first-1&#34;&gt;first()&lt;/h3&gt;
&lt;p&gt;first()速度相比其他方法最快&lt;/p&gt;
&lt;h2 id=&#34;data-type-in-rdd&#34;&gt;Data Type in RDD&lt;/h2&gt;
&lt;p&gt;RDD中存放的数据类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基本类型，String，对象&lt;/li&gt;
&lt;li&gt;KV类型&lt;/li&gt;
&lt;li&gt;数字类型&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;practice&#34;&gt;Practice&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;process&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//1. 创建sc对象
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkConf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setMaster&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;local[6]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setAppName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;practice&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//2. 读取文件
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//1,2010,1,1,0,4,NA,NA,NA,NA,-21,43,1021,-11,NW,1.79,0,0
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;textFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;dataset/parctive.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//3. 处理数据
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;resultRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)),&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;StringUtils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isNotEmpty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;equalsIgnoreCase&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;NA&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toInt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sortBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//4. 获取结果
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;19&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;resultRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;take&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;20&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt;21&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//5. 关闭sc
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;23&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;rdd-feature&#34;&gt;RDD Feature&lt;/h2&gt;
&lt;h3 id=&#34;rdds-shuffle-and-partition&#34;&gt;RDD&#39;s shuffle and partition&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;RDD经常需要通过读取外部系统的数据来创建，外部存储系统往往是支持分片的。RDD需要支持分区，来和外部系统的分片一一对应&lt;/li&gt;
&lt;li&gt;RDD的分区是一个并行计算的实现手段&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;partition-function&#34;&gt;partition function&lt;/h4&gt;
&lt;p&gt;RDD使用分区来分布式处理，当使用RDD读取数据时，会尽量在屋里上靠近数据源。比如读HDFS或Cassandra时，会尽量的保持RDD的分区和数据源的分区数，分区模式一一对应&lt;/p&gt;
&lt;h4 id=&#34;shuffle&#34;&gt;shuffle&lt;/h4&gt;
&lt;p&gt;从mapper端到reducer端&lt;/p&gt;
&lt;p&gt;Spark支持宽依赖的转换，例如groupByKey和reduceByKey。在这些依赖项中，计算单个分区中的记录所需的数据可以来自于父数据集的许多分区中。要执行这些转换，具有相同key的所有元组必须最终位于同一分区中，由同一任务处理。为了满足这一要求，Spark产生一个shuffle，它在集群内部传输数据，并产生一个带有一组新分区的新stage。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hash base shuffle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Reduce 找到每个Mapper中对应自己哈希桶拉取数据&lt;/p&gt;
&lt;p&gt;缺点：过多占用资源占用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sort base shuffle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;先按照partition ID 排序， 后按照Key的HashCode排序&lt;/p&gt;
&lt;h4 id=&#34;partition-and-shuffle-relation&#34;&gt;partition and shuffle relation&lt;/h4&gt;
&lt;p&gt;分区主要用来实现并行计算，和shuffle没什么关系，但数据处理时，例如reduceByKey，groupByKey等聚合操作，需要把Key相同的Value拉取到一起进行计算，这个时候因为这些Key的相同的Value可能会在不同的分区，所以理解分区才能理解shuffle的根本原理&lt;/p&gt;
&lt;h4 id=&#34;shuffle-feature&#34;&gt;shuffle feature&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;只有KV型的RDD才会有Shuffle操作&lt;/li&gt;
&lt;li&gt;早期版本spark的shuffle算法是 hash base shuffle，后来改为 sort base shuffle，更适合大吞吐量的场景&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;check-partition&#34;&gt;check partition&lt;/h4&gt;
&lt;p&gt;指定分区数&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过本地集合创建的时候指定分区数&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkConf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setMaster&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;local[6]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setAppName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;practice&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//创建App并开启6个分区
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;通过读取文件创建的时候指定分区数&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;//指定分区数3
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;testFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;hdfs://node01:8020/data/test.txt&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;//这里指定的是最小分区数6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;查看方法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过WebUI查看。端口：4040&lt;/li&gt;
&lt;li&gt;通过partitions来查看。rdd1.partitions.size&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;重分区&#34;&gt;重分区&lt;/h4&gt;
&lt;p&gt;coalesce(num, true)&lt;/p&gt;
&lt;p&gt;repartitions(num)&lt;/p&gt;
&lt;h3 id=&#34;rdd-cache&#34;&gt;RDD Cache&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1. 取出IP
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;countRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2. 数据清洗
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cleanRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;countRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;StingUtils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isNotEmpty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//3. 统计ip的出现次数
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cleanRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceBykey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//4. 统计出现最少的ip
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leastIP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sortBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//5. 统计出现最多的ip
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mostIP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sortBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;leastIP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mostIP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;第一次统计job（一个Action算子）执行了两个shuffle(reduceByKey，sortByKey)&lt;/p&gt;
&lt;p&gt;第二次统计job（一个Action算子）执行了两个shuffle(reduceByKey，sortByKey)&lt;/p&gt;
&lt;p&gt;转换算子的作用：生成RDD，以及RDD之间的依赖关系&lt;/p&gt;
&lt;p&gt;Action算子的作用：生成job，执行job&lt;/p&gt;
&lt;p&gt;全局执行了四个shuffle&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用缓存的意义：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;减少shuffle操作&lt;/li&gt;
&lt;li&gt;容错，减少开销：rdd1-&amp;gt;rdd2-&amp;gt;rdd3，若rdd3算错会再次计算rdd1和rdd2整个流程。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;缓存API:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;cache()或persist(null/level)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1. 处理
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;countRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cleanRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;countRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;StingUtils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isNotEmpty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cleanRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceBykey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2. cache
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cache&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//3. 两个RDD的action操作
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leastIP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sortBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mostIP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sortBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;leastIP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mostIP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1. 处理
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;countRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cleanRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;countRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;StingUtils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isNotEmpty&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cleanRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceBykey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2. cache
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;persist&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;storageLevel&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;MEMORY_ONLY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//3. 两个RDD的action操作
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;leastIP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sortBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mostIP&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aggRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sortBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;first&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;leastIP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mostIP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;缓存级别：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MEMORY_ONLY: CPU效率最高&lt;/p&gt;
&lt;p&gt;MEMORY_ONLY_SER: 更加节省空间&lt;/p&gt;
&lt;h3 id=&#34;checkpoint&#34;&gt;Checkpoint&lt;/h3&gt;
&lt;p&gt;斩断RDD的依赖链，并且将数据存储在可靠的存储引擎中，例如HDFS&lt;/p&gt;
&lt;p&gt;HDFS的NameNode中主要职责就是维护两个文件，一个是edits，另一个是fsimage。&lt;/p&gt;
&lt;p&gt;edits中主要存放Editlog，FsImage保存了当前系统中所有目录和文件的信息，这个FsImage其实就是一个Checkpoint。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每一次修改文件的时候，都会在Edits中添加一条记录。&lt;/li&gt;
&lt;li&gt;在一定条件满足的情况下，把edits删掉添加一个新的FSimage，包含了系统当前最新的状态。好处：增加速度，提高稳定性&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Checkpoint和Cache的区别：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cache可以吧RDD计算出来放到内存中，但RDD的依赖链(相当于NameNode中的Edits日志)是不能丢的，若出现错误，只能重计算出来。&lt;/p&gt;
&lt;p&gt;Checkpoint把结果存放在HDFS这类存储中，就变成了可靠的数据，如果出错了，则通过复制HDFS中的文件来实现容错。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;如何使用：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;两步：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;SparkConf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setMaster&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;local[6]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setAppName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;debug_string&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1. setCheckPointDir：设置保存目录，也可以设置为HDFS上的目录
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setCheckpointDir&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;checkpoint&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interimRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;textFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;dataset/test.txt&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;				&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;				&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;StringUtils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isNotBlank&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;				&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2. setCheckPoint：是一个action操作，也就是说如果调用checkpoint，则会重新计算一下RDD，然后把结果存在HDFS或者本地目录中
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;interimRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;checkpoint&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;interimRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;spark-running-process&#34;&gt;Spark Running Process&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1. 创建sc对象
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2. 创建数据集
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;textRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;hadoop spark&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;hadoop flume&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;spark soo&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//3. 数据处理
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//	1.拆词2.赋予初始词频3.聚合4.将结果转为字符串
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;splitRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;textRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flatMap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tupleRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;splitRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reduceRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tupleRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;strRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reduceRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//4. 结果获取
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//5. 关闭sc
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;集群组成&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Node1主节点:&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Master Daemon&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;负责管理Master节点， 协调资源的获取，以及连接Worker节点来运行Executor，是spark集群中的协调节点&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Node2:&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Worker Daemon&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;也称之为Slaves，是spark集群中的计算节点，用于和Master交互和并管理Driver， 当一个spark job 提交后，会创建sparkContext，worker会启动对应的Executor&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Driver&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;ction算子操作获取的结果，会把结果存放在Driver中&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Executor Backend&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;Worker用于控制Executor的启停，其实worker是通过 Executor Backend来进行控制的。 Executor Backend是一个进程（是一个JVM实例），持有一个Executor对象。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Executor&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Task1   Task2   Task3&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;逻辑执行图&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;textRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;hadoop spark&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;hadoop flume&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;spark soo&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;splitRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;textRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flatMap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tupleRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;splitRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reduceRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tupleRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;strRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reduceRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toDebugString&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;MapPartitionsRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;map&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scala&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;12&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;kt&#34;&gt;ShuffledRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scala&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;11&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;+-&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;MapPartitionsRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;map&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scala&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;kt&#34;&gt;MapPartitionsRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flatMap&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scala&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;9&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;[]&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;|&lt;/span&gt;  &lt;span class=&#34;kt&#34;&gt;ParallelCollectionRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;at&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scala&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;[]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210527sparkGuide2/RDDlogic.png&#34; alt=&#34;RDDlogic&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;物理执行图&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当触发Action执行的时候，这一组互相依赖的RDD要被处理，所以要转化为可运行的物理执行图，调度到集群中执行。&lt;/p&gt;
&lt;p&gt;因为大部分RDD是不真正存放数据的，只是数据从中流转，所以不能直接在集群中运行RDD，要有一种pipeline的思想，需要将这组RDD转为Stage和Task，从而运行Task，优化整体执行速度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210527sparkGuide2/RDDphysic.png&#34; alt=&#34;RDDphysic&#34;&gt;&lt;/p&gt;
&lt;p&gt;小结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;① -&amp;gt; ① -&amp;gt; ① 在第一个stage中，每一个这样的执行流程是一个Task，也就是在同一个Stage中的所有RDD的对应分区，在同一个Task中执行&lt;/li&gt;
&lt;li&gt;Stage的划分是由Shuffle操作来确定的，有Shuffle的地方，Stage断开&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;数据流动&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;textRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hadoop Spark&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Hadoop Flume&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Spark Squad&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;splitRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;textRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flatMap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tupleRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;splitRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reduceRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tupleRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;strRDD&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reduceRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;s&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Job和Stage的关系&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Job是一个最大的调度单位，DAGScheduler会首先创建一个Job的相关信息，然后去调度Job，但是没办法直接调度Job。&lt;/p&gt;
&lt;p&gt;​	&lt;strong&gt;为什么Job需要切分&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;因为job的含义是对整个RDD求值，但RDD之间可能有一些宽依赖&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果遇到宽依赖的话，两个RDD之间需要进行数据拉取和复制&lt;/p&gt;
&lt;p&gt;那么一个RDD就必须等待它所依赖的RDD所有分区先计算完成，然后再进行拉取&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所以，一个Job是无法计算完整的RDD血统的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​	&lt;strong&gt;Stage和Task的关系&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Stage中的RDD之间是窄依赖：&lt;/p&gt;
&lt;p&gt;窄依赖RDD理论上可以放在同一个Pipeline中执行的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RDD还有分区：&lt;/p&gt;
&lt;p&gt;一个RDD只是一个概念，而真正存放和处理数据时，都是以分区作为单位的&lt;/p&gt;
&lt;p&gt;Stage对应的是多个整体上的RDD，而真正的运行是需要针对RDD的分区来进行的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一个Task对应一个RDD的分区：&lt;/p&gt;
&lt;p&gt;一个比Stage粒度更细的单元叫做Task，Stage是由Task组成的，之所以有Task这个概念，是因为Stage针对整个RDD，而计算的时候，要针对RDD的分区。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Job&amp;gt;Stage&amp;gt;Task&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一个Job由多个Stage组成(这个取决有多少个宽依赖)，一个Stage由多个Task组成（这个取决有多少个分区数量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;而Stage中经常会有一组Task需要同时执行，所以针对每一个Task来进行调度太过频繁没有意义，所以每个Stage中的Task们会被收集起来，放入一个TaskSet集合中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一个Stage有一个TaskSet&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TaskSet中Task的个数由Stage中的最大分区数决定&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/20210527sparkGuide2/sparkFlow.png&#34; alt=&#34;sparkFlow&#34;&gt;&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>应用架构演进历程: The Development of App Architecture</title>
      <link>https://Jerrysmd.github.io/post/20210526apparchitecturedevelopment/apparchitecturedevelopment/</link>
      <pubDate>Wed, 26 May 2021 17:17:50 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210526apparchitecturedevelopment/apparchitecturedevelopment/</guid>
      <description>
        
          &lt;p&gt;The features of large applications: high availability, high concurrency and big data. High availability: system need to provide service without interruption. High concurrency: still stable under the big access. Big data: store and manage big data well.&lt;/p&gt;
&lt;h2 id=&#34;最简单的架构&#34;&gt;最简单的架构&lt;/h2&gt;
&lt;p&gt;开始数据量少，所以只需一台服务器&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210526appArchitectureDevelopment/smapleArchitecture.png&#34; alt=&#34;smapleArchitecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;应用程序、文件、数据库往往都部署在一台服务器上，应用程序部署在Tomcat服务器上，数据库可以使用MySQL&lt;/p&gt;
&lt;h2 id=&#34;应用于数据服务分隔&#34;&gt;应用于数据服务分隔&lt;/h2&gt;
&lt;p&gt;随着业务越来越复杂，访问量越来越大，导致性能越来越差，存储空间严重不足，这时我们考虑把服务器增加到三台。分离出应用服务器、数据库服务器、文件服务器。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用服务器需要处理大量的访问，所以需要性能更好的CPU&lt;/li&gt;
&lt;li&gt;数据库服务器需要存储大量的数据以及快速的检索，所以需磁盘的检索速度较快以及存储空间大&lt;/li&gt;
&lt;li&gt;文件服务器需要存储上传的文件，需要更大的磁盘；现在通常情况下会选择第三方的存储服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210526appArchitectureDevelopment/appSeparateData.png&#34; alt=&#34;appSeparateData&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;应用服务器集群&#34;&gt;应用服务器集群&lt;/h2&gt;
&lt;p&gt;在高并发、大流量的情况下，一台服务器是肯定处理不过来的，这个时候增加服务器，部署集群提供服务，来分担每台服务器的压力。部署集群的另一个好处是可伸缩性。比如双十一增加服务器分摊流量，双十一过后再减少服务器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210526appArchitectureDevelopment/Cluster.png&#34; alt=&#34;Cluster&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果应用服务器是Tomcat，那么可以部署一个Tomcat的集群，外部在部署一个负载均衡器，可以采用随机、轮询或者一致性哈希算法达将用户的请求分发到不同应用服务集群；通常选择的免费的负载均衡是nginx。在这种架构下，应用服务器的负载将不会是整个应用的瓶颈点；&lt;/p&gt;
&lt;p&gt;虽然应用程序的处理速度在这种架构下提升了许多，但是又会暴露一个问题，数据库的压力大大增大，导致访问响应延迟，影响整个应用的性能。这种架构还有个问题，通常应用是有状态的，需要记录用户的登录信息，如果每次用户的请求都是随机路由到后端的应用服务器，那么用户的会话将会丢失；解决这个问题两个方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用一致性hash把用户的请求路由到同一个Tomcat，如果有一台服务器跪了，那么这台服务器上面的用户信息将会丢失&lt;/li&gt;
&lt;li&gt;Tomcat集群之间通过配置session复制，达到共享，此方案效率较低&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;缓存&#34;&gt;缓存&lt;/h2&gt;
&lt;p&gt;根据二八原则，80%的的业务都是集中访问20%的数据，这20%的数据通常称为热点数据，但是这20%的数据占用的内存也不会小，如果每个应用服务器都存放一份，有些浪费存储空间，所以这时候需要考虑加入分布式缓存服务器（常用的是Redis）；当引入了分布式缓存服务器，再来看上面那个方案的问题，就可以解决了，把用户的会话存放到缓存服务器，不仅可以防止用户数据丢失，效率也不低；架构图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210526appArchitectureDevelopment/cache.png&#34; alt=&#34;cache&#34;&gt;&lt;/p&gt;
&lt;p&gt;由于分布式缓存服务器毕竟存放在远程，需要经过网络，所以取数据还是要花一点时间；本地缓存访问速度更快，但是内存空间有限，并且还会出现和应用程序争抢资源；所以这种架构搭配了分布式缓存和本地缓存，本地缓存存放少量常用热点数据，当本地缓存中没有命中时在去集中式缓存取&lt;/p&gt;
&lt;p&gt;在引进缓存之后，数据库的访问压力可以的一定的缓解&lt;/p&gt;
&lt;h2 id=&#34;数据库读写分离&#34;&gt;数据库读写分离&lt;/h2&gt;
&lt;p&gt;虽然在加入了缓存之后，部分数据可以直接走缓存，不需要访问数据库，但是任然会有一些请求，会访问数据库，比如：缓存失效，缓存未命中；当流量大的时候，数据库的访问量也不小。这时候我们需要考虑搭建数据库集群，读写分离&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210526appArchitectureDevelopment/rwSeparate.png&#34; alt=&#34;rwSeparate&#34;&gt;&lt;/p&gt;
&lt;p&gt;当应用服务器有写操作时，访问主库，当应用程序有读操作时，访问从库；大多数的应用都是读的操作远远大于写的操作，所以可以配置数据库一主多从来分担数据库的压力；为了让应用程序对应主库和从库无感知，通常需要引入一些读写分离的框架做一个统一的数据访问模块。&lt;/p&gt;
&lt;p&gt;这种架构通常需要警惕的一个问题是主从延迟，当在高并发的场景下，主库刚写成功，数据库还未成功同步完从库，这时候另一个请求进入读取数据发现不存在；解放方案是在应用程序中高并发的场景下设置强制走主库查询&lt;/p&gt;
&lt;h2 id=&#34;反向代理和cdn&#34;&gt;反向代理和CDN&lt;/h2&gt;
&lt;p&gt;假如随着业务的不断扩大，全国各地都会使用到我们的应用，由于各地区的网络情况不同，所以有的人请求响应速度快，有的人请求响应速度慢，这会严重的影响到用户的体验。为了提高响应速度需要引入反向代理和CDN；CDN和反向代理都是采用的缓存，目的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;尽可能快的把数据呈现给用户&lt;/li&gt;
&lt;li&gt;减轻后端服务器的压力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;架构图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210526appArchitectureDevelopment/cdn.png&#34; alt=&#34;cdn&#34;&gt;&lt;/p&gt;
&lt;p&gt;CDN: 部署在网络提供商的机房，当用户来访问的时候，从距离用户最近的服务器返回数据，尽快呈现给用户；通常情况下在CDN中缓存的是静态资源（html,js,css），达到动静分离；但是有时候遇到了某些数据访问量特别大的时候，后端会生成静态资源放入到CDN，比如：商城的首页，每个用户进入都需要访问的页面，如果每次请求都进入到后端，那么服务器的压力肯定不小，这种情况下会把首页生成静态的文件缓存到cdn和反向代理服务器&lt;/p&gt;
&lt;p&gt;反向代理：部署在应用的中心机房，通常也是缓存的静态资源，当用户通过CDN未请求到需要的数据时，先进入反向代理服务器，如果有缓存用户访问的数据，那么直接返回给用户；这里也有特殊情况，对于有些场景下的热点数据，在这里根据用户的请求去分布式缓存服务器中获取，能拿到就直接返回。&lt;/p&gt;
&lt;p&gt;这种架构已经把缓存做到了4级&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一级：CDN 缓存静态资源&lt;/li&gt;
&lt;li&gt;第二级：反向代理缓存静态资源以及部分热点数据&lt;/li&gt;
&lt;li&gt;第三级：应用服务器的本地缓存&lt;/li&gt;
&lt;li&gt;第四级：分布式缓存服务器&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常情况下经过了这4级缓存，能够进入到数据库的请求也不多了，很好的释放了数据库的压力&lt;/p&gt;
&lt;h2 id=&#34;搜索引擎和nosql&#34;&gt;搜索引擎和NoSQL&lt;/h2&gt;
&lt;p&gt;随着业务的不断扩大，对于数据的存储和查询的需求也越来越复杂，通常情况我们需要引入非关系型数据库，比如搜索引擎和NoSQL数据库&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210526appArchitectureDevelopment/NoSQL.png&#34; alt=&#34;NoSQL&#34;&gt;&lt;/p&gt;
&lt;p&gt;有时候我们的查询场景很复杂，需要查询很多数据表，经过一系列的计算才能完成，这时候可以考虑通过数据同步工具（比如canal）拉去数据到大数据平台，使用批处理框架离线计算，把输出的结果存放到搜索引擎或者NoSQL数据库中，应用程序直接查询计算的结果返回给用户。也有可能我们需要汇总多个表的数据做一张宽表，方便应用程序查询&lt;/p&gt;
&lt;p&gt;由于引入的数据存储方式增多，为了减轻应用程序的管理多个数据源的麻烦，需要封装统一数据访问模块，如果使用的时Java，可以考虑spring-data&lt;/p&gt;
&lt;h2 id=&#34;业务纵向拆分&#34;&gt;业务纵向拆分&lt;/h2&gt;
&lt;p&gt;互联网公司通常的宗旨是小步迭代试错快跑，当业务发展到足够大，对于单体应用想要达到这个宗旨是有难度的，随着业务的发展，应用程序越来越大，研发、维护、发布的成本也越来越大，这时候就需要考虑根据业务把单体应用拆分为多个服务，服务之间可以通过RPC远程调用和消息队列来一起完成用户的请求。&lt;/p&gt;
&lt;p&gt;由于业务的拆分，通常情况下也会相应的对数据库进行拆分，达到一个服务对应一个数据库的理想状态&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210526appArchitectureDevelopment/vertical.png&#34; alt=&#34;vertical&#34;&gt;&lt;/p&gt;
&lt;p&gt;引入MQ的好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提高系统的可用性：当消费服务器发送故障时，消息还在消息队列中，数据不会丢失&lt;/li&gt;
&lt;li&gt;加快请求的响应：当用户请求到达服务器后，把请求中可以异步处理的数据放入到MQ，让系统逐一消费，不需要用户等待，加快了响应速度&lt;/li&gt;
&lt;li&gt;削峰填谷：当大量请求都同时进入到系统之后，会全部放入到消息队列，系统逐一消费，不会对系统造成很大的冲击&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;还有一个情况未谈及到，就是数据库的水平拆分，这也是数据库拆分的最后手段，只有当单表数据特别大，不能满足业务的需要才使用。使用最多的还是进行数据库的业务纵向拆分，把数据库中不同业务的数据放到不同的物理服务器上。&lt;/p&gt;
&lt;p&gt;应用当前到底选择什么架构，一定要根据实际业务的需求进行灵活的选择，驱动技术架构发展的主要动力还是在于业务的发展，不要为了技术而技术。&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>Zookeeper核心知识点: Key points of ZooKeeper</title>
      <link>https://Jerrysmd.github.io/post/20210519zookeeper/zookeeper/</link>
      <pubDate>Wed, 19 May 2021 16:07:17 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210519zookeeper/zookeeper/</guid>
      <description>
        
          &lt;p&gt;ZooKeeper is an open source distributed coordination framework. It is positioned to provide consistent services for distributed applications and is the administrator of the entire big data system. ZooKeeper will encapsulate key services that are complex and error-prone, and provide users with efficient, stable, and easy-to-use services.&lt;/p&gt;
&lt;h2 id=&#34;1-introduce&#34;&gt;1. Introduce&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;ZooKeeper&lt;/strong&gt; 是一个开源的&lt;strong&gt;分布式协调框架&lt;/strong&gt;，它的定位是为分布式应用提供一致性服务，是整个大数据体系的&lt;strong&gt;管理员&lt;/strong&gt;。&lt;strong&gt;ZooKeeper&lt;/strong&gt; 会封装好复杂易出错的关键服务，将高效、稳定、易用的服务提供给用户使用。&lt;/p&gt;
&lt;p&gt;如果上面的官方言语你不太理解，你可以认为 &lt;strong&gt;ZooKeeper&lt;/strong&gt; = &lt;strong&gt;文件系统&lt;/strong&gt; + &lt;strong&gt;监听通知机制&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;11-file-system&#34;&gt;1.1 File System&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210519zookeeper/1.png&#34; alt=&#34;filesys&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt;维护一个类似文件系统的树状数据结构，这种特性使得 &lt;strong&gt;Zookeeper&lt;/strong&gt; 不能用于存放大量的数据，每个节点的存放数据上限为&lt;strong&gt;1M&lt;/strong&gt;。每个子目录项如 NameService 都被称作为 &lt;strong&gt;znode&lt;/strong&gt;(目录节点)。和文件系统一样，我们能够自由的增加、删除&lt;strong&gt;znode&lt;/strong&gt;，在一个&lt;strong&gt;znode&lt;/strong&gt;下增加、删除子&lt;strong&gt;znode&lt;/strong&gt;，唯一的不同在于&lt;strong&gt;znode&lt;/strong&gt;是可以存储数据的。默认有四种类型的&lt;strong&gt;znode&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;持久化目录节点 PERSISTENT&lt;/strong&gt;：客户端与zookeeper断开连接后，该节点依旧存在。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持久化顺序编号目录节点 PERSISTENT_SEQUENTIAL&lt;/strong&gt;：客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;临时目录节点 EPHEMERAL&lt;/strong&gt;：客户端与zookeeper断开连接后，该节点被删除。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;临时顺序编号目录节点 EPHEMERAL_SEQUENTIAL&lt;/strong&gt;：客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;12-watcher&#34;&gt;1.2 Watcher&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Watcher&lt;/strong&gt; 监听机制是 &lt;strong&gt;Zookeeper&lt;/strong&gt; 中非常重要的特性，我们基于  &lt;strong&gt;Zookeeper&lt;/strong&gt; 上创建的节点，可以对这些节点绑定&lt;strong&gt;监听&lt;/strong&gt;事件，比如可以监听节点数据变更、节点删除、子节点状态变更等事件，通过这个事件机制，可以基于  &lt;strong&gt;Zookeeper&lt;/strong&gt; 实现分布式锁、集群管理等功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Watcher&lt;/strong&gt; 特性：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当数据发生变化的时候，  &lt;strong&gt;Zookeeper&lt;/strong&gt; 会产生一个 &lt;strong&gt;Watcher&lt;/strong&gt; 事件，并且会发送到客户端。但是客户端只会收到一次通知。如果后续这个节点再次发生变化，那么之前设置 &lt;strong&gt;Watcher&lt;/strong&gt; 的客户端不会再次收到消息。（&lt;strong&gt;Watcher&lt;/strong&gt; 是一次性的操作）。可以通过循环监听去达到永久监听效果。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ZooKeeper 的 Watcher 机制，总的来说可以分为三个过程：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;客户端注册 Watcher，注册 watcher 有 3 种方式，getData、exists、getChildren。&lt;/li&gt;
&lt;li&gt;服务器处理 Watcher 。&lt;/li&gt;
&lt;li&gt;客户端回调 Watcher 客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210519zookeeper/2.webp&#34; alt=&#34;watcher&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;监听流程&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;首先要有一个main()线程&lt;/li&gt;
&lt;li&gt;在main线程中创建Zookeeper客户端，这时就会创建两个线程，一个负责网络连接通信（connet），一个负责监听（listener）。&lt;/li&gt;
&lt;li&gt;通过connect线程将注册的监听事件发送给Zookeeper。&lt;/li&gt;
&lt;li&gt;在Zookeeper的注册监听器列表中将注册的监听事件添加到列表中。&lt;/li&gt;
&lt;li&gt;Zookeeper监听到有数据或路径变化，就会将这个消息发送给listener线程。&lt;/li&gt;
&lt;li&gt;listener线程内部调用了process()方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;13-feature&#34;&gt;1.3 Feature&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210519zookeeper/3.png&#34; alt=&#34;feature&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;集群&lt;/strong&gt;：Zookeeper是一个领导者（Leader），多个跟随者（Follower）组成的集群。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高可用性&lt;/strong&gt;：集群中只要有半数以上节点存活，Zookeeper集群就能正常服务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全局数据一致&lt;/strong&gt;：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更新请求顺序进行&lt;/strong&gt;：来自同一个Client的更新请求按其发送顺序依次执行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据更新原子性&lt;/strong&gt;：一次数据更新要么成功，要么失败。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实时性&lt;/strong&gt;：在一定时间范围内，Client能读到最新数据。&lt;/li&gt;
&lt;li&gt;从&lt;code&gt;设计模式&lt;/code&gt;角度来看，zk是一个基于&lt;strong&gt;观察者设计模式&lt;/strong&gt;的框架，它负责管理跟存储大家都关心的数据，然后接受观察者的注册，数据反生变化zk会通知在zk上注册的观察者做出反应。&lt;/li&gt;
&lt;li&gt;Zookeeper是一个分布式协调系统，满足CP性，跟&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI4NjI1OTI4Nw==&amp;amp;mid=2247487072&amp;amp;idx=1&amp;amp;sn=3010908c4b668edef8fbd1f320343354&amp;amp;scene=21#wechat_redirect&#34;&gt;SpringCloud&lt;/a&gt;中的Eureka满足AP不一样。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;分布式协调系统：Leader会同步数据到follower，用户请求可通过follower得到数据，这样不会出现单点故障，并且只要同步时间无限短，那这就是个好的 分布式协调系统。&lt;/li&gt;
&lt;li&gt;CAP原则又称CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;2-function&#34;&gt;2. Function&lt;/h2&gt;
&lt;p&gt;通过对 Zookeeper 中丰富的数据节点进行交叉使用，配合 &lt;strong&gt;Watcher&lt;/strong&gt; 事件通知机制，可以非常方便的构建一系列分布式应用中涉及的核心功能，比如 &lt;strong&gt;数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列&lt;/strong&gt; 等功能。&lt;/p&gt;
&lt;h3 id=&#34;1-数据发布订阅&#34;&gt;1. 数据发布/订阅&lt;/h3&gt;
&lt;p&gt;当某些数据由几个机器共享，且这些信息经常变化数据量还小的时候，这些数据就适合存储到ZK中。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据存储&lt;/strong&gt;：将数据存储到 Zookeeper 上的一个数据节点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据获取&lt;/strong&gt;：应用在启动初始化节点从 Zookeeper 数据节点读取数据，并在该节点上注册一个数据变更 &lt;strong&gt;Watcher&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据变更&lt;/strong&gt;：当变更数据时会更新 Zookeeper 对应节点数据，Zookeeper会将数据变更&lt;strong&gt;通知&lt;/strong&gt;发到各客户端，客户端接到通知后重新读取变更后的数据即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-分布式锁&#34;&gt;2. 分布式锁&lt;/h3&gt;
&lt;p&gt;关于分布式锁其实在 &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI4NjI1OTI4Nw==&amp;amp;mid=2247488832&amp;amp;idx=1&amp;amp;sn=5999893d7fe773f54f7d097ac1c2074d&amp;amp;scene=21#wechat_redirect&#34;&gt;&lt;strong&gt;Redis&lt;/strong&gt;&lt;/a&gt; 中已经讲过了，并且Redis提供的分布式锁是比ZK性能强的。基于ZooKeeper的分布式锁一般有如下两种。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;保持独占&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;核心思想&lt;/strong&gt;：在zk中有一个唯一的临时节点，只有拿到节点的才可以操作数据，没拿到的线程就需要等待。&lt;strong&gt;缺点&lt;/strong&gt;：可能引发&lt;code&gt;羊群效应&lt;/code&gt;，第一个用完后瞬间有999个同时并发的线程向zk请求获得锁。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;控制时序&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;主要是避免了羊群效应，临时节点已经预先存在，所有想要获得锁的线程在它下面创建临时顺序编号目录节点，编号最小的获得锁，用完删除，后面的依次排队获取。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210519zookeeper/4.png&#34; alt=&#34;distributedLock&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-负载均衡&#34;&gt;3. 负载均衡&lt;/h3&gt;
&lt;p&gt;多个相同的jar包在不同的服务器上开启相同的服务，可以通过nginx在服务端进行负载均衡的配置。也可以通过ZooKeeper在客户端进行负载均衡配置。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多个服务注册&lt;/li&gt;
&lt;li&gt;客户端获取中间件地址集合&lt;/li&gt;
&lt;li&gt;从集合中随机选一个服务执行任务&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;ZooKeeper负载均衡和Nginx负载均衡区别&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ZooKeeper&lt;/strong&gt;不存在单点问题，zab机制保证单点故障可重新选举一个leader只负责服务的注册与发现，不负责转发，减少一次数据交换（消费方与服务方直接通信），需要自己实现相应的负载均衡算法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nginx&lt;/strong&gt;存在单点问题，单点负载高数据量大,需要通过 &lt;strong&gt;KeepAlived&lt;/strong&gt; + &lt;strong&gt;LVS&lt;/strong&gt; 备机实现高可用。每次负载，都充当一次中间人转发角色，增加网络负载量（消费方与服务方间接通信），自带负载均衡算法。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;4-命名服务&#34;&gt;4. 命名服务&lt;/h3&gt;
&lt;p&gt;命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk 创建一个全局唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。&lt;/p&gt;
&lt;h3 id=&#34;5-分布式协调通知&#34;&gt;5. 分布式协调/通知&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;对于系统调度来说，用户更改zk某个节点的value， ZooKeeper会将这些变化发送给注册了这个节点的 watcher 的所有客户端，进行通知。&lt;/li&gt;
&lt;li&gt;对于执行情况汇报来说，每个工作进程都在目录下创建一个携带工作进度的临时节点，那么汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;6-集群管理&#34;&gt;6. 集群管理&lt;/h3&gt;
&lt;p&gt;大数据体系下的大部分集群服务好像都通过&lt;strong&gt;ZooKeeper&lt;/strong&gt;管理的，其实管理的时候主要关注的就是机器的动态上下线跟&lt;strong&gt;Leader&lt;/strong&gt;选举。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;动态上下线：&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;比如在&lt;strong&gt;zookeeper&lt;/strong&gt;服务器端有一个&lt;strong&gt;znode&lt;/strong&gt;叫 &lt;strong&gt;/Configuration&lt;/strong&gt;，那么集群中每一个机器启动的时候都去这个节点下创建一个&lt;strong&gt;EPHEMERAL&lt;/strong&gt;类型的节点，比如&lt;strong&gt;server1&lt;/strong&gt; 创建 &lt;strong&gt;/Configuration/Server1&lt;/strong&gt;，&lt;strong&gt;server2&lt;/strong&gt;创建**/Configuration /Server1**，然后**Server1**和**Server2**都**watch** **/Configuration** 这个父节点，那么也就是这个父节点下数据或者子节点变化都会通知到该节点进行**watch**的客户端。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Leader选举：&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;利用ZooKeeper的&lt;strong&gt;强一致性&lt;/strong&gt;，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /Master 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选举了。&lt;/li&gt;
&lt;li&gt;就是动态Master选举。这就要用到 &lt;strong&gt;EPHEMERAL_SEQUENTIAL&lt;/strong&gt;类型节点的特性了，这样每个节点会&lt;code&gt;自动被编号&lt;/code&gt;。允许所有请求都能够创建成功，但是得有个创建顺序，每次选取序列号&lt;strong&gt;最小&lt;/strong&gt;的那个机器作为&lt;strong&gt;Master&lt;/strong&gt; 。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;3-choose-leader&#34;&gt;3. Choose Leader&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;ZooKeeper&lt;/strong&gt;集群节点个数一定是&lt;strong&gt;奇数&lt;/strong&gt;个，一般3个或者5个就OK。为避免集群群龙无首，一定要选个大哥出来当Leader。这是个高频考点。&lt;/p&gt;
&lt;h3 id=&#34;31-预备知识&#34;&gt;3.1 预备知识&lt;/h3&gt;
&lt;h5 id=&#34;311-节点四种状态&#34;&gt;3.1.1. 节点四种状态。&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;LOOKING&lt;/strong&gt;：寻 找 Leader 状态。当服务器处于该状态时会认为当前集群中没有 Leader，因此需要进入 Leader 选举状态。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FOLLOWING&lt;/strong&gt;：跟随者状态。处理客户端的非事务请求，转发事务请求给 Leader 服务器，参与事务请求 Proposal(提议) 的投票，参与 Leader 选举投票。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LEADING&lt;/strong&gt;：领导者状态。事务请求的唯一调度和处理者，保证集群事务处理的顺序性，集群内部个服务器的调度者(管理follower,数据同步)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OBSERVING&lt;/strong&gt;：观察者状态。3.0 版本以后引入的一个服务器角色，在不影响集群事务处理能力的基础上提升集群的非事务处理能力，处理客户端的非事务请求，转发事务请求给 Leader 服务器，不参与任何形式的投票。&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;312-服务器id&#34;&gt;3.1.2 服务器ID&lt;/h5&gt;
&lt;p&gt;既&lt;strong&gt;Server id&lt;/strong&gt;，一般在搭建ZK集群时会在&lt;strong&gt;myid&lt;/strong&gt;文件中给每个节点搞个唯一编号，&lt;code&gt;编号越大在Leader选择算法中的权重越大&lt;/code&gt;，比如初始化启动时就是根据服务器ID进行比较。&lt;/p&gt;
&lt;h3 id=&#34;313--zxid&#34;&gt;3.1.3  ZXID&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ZooKeeper&lt;/strong&gt; 采用全局递增的事务 Id 来标识，所有 proposal(提议)在被提出的时候加上了&lt;strong&gt;ZooKeeper Transaction Id&lt;/strong&gt; ，zxid是64位的Long类型，&lt;strong&gt;这是保证事务的顺序一致性的关键&lt;/strong&gt;。zxid中高32位表示纪元&lt;strong&gt;epoch&lt;/strong&gt;，低32位表示事务标识&lt;strong&gt;xid&lt;/strong&gt;。你可以认为zxid越大说明存储数据越新。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个leader都会具有不同的&lt;strong&gt;epoch&lt;/strong&gt;值，表示一个纪元/朝代，用来标识 &lt;strong&gt;leader&lt;/strong&gt; 周期。每个新的选举开启时都会生成一个新的&lt;strong&gt;epoch&lt;/strong&gt;，新的leader产生的话&lt;strong&gt;epoch&lt;/strong&gt;会自增，会将该值更新到所有的zkServer的&lt;strong&gt;zxid&lt;/strong&gt;和&lt;strong&gt;epoch&lt;/strong&gt;，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;xid&lt;/strong&gt;是一个依次递增的事务编号。数值越大说明数据越新，所有 proposal（提议）在被提出的时候加上了&lt;strong&gt;zxid&lt;/strong&gt;，然后会依据数据库的&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI4NjI1OTI4Nw==&amp;amp;mid=2247485515&amp;amp;idx=1&amp;amp;sn=60763ddda77928943bfd3d57e0c9256e&amp;amp;scene=21#wechat_redirect&#34;&gt;两阶段过程&lt;/a&gt;，首先会向其他的 server 发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;32-leader选举&#34;&gt;3.2 Leader选举&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Leader&lt;/strong&gt;的选举一般分为&lt;strong&gt;启动时选举&lt;/strong&gt;跟Leader挂掉后的&lt;strong&gt;运行时选举&lt;/strong&gt;。&lt;/p&gt;
&lt;h5 id=&#34;321-启动时leader选举&#34;&gt;3.2.1 启动时Leader选举&lt;/h5&gt;
&lt;p&gt;我们以5台机器为例，只有超过半数以上，即最少启动3台服务器，集群才能正常工作。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;服务器1启动，发起一次选举。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;服务器1投自己一票。此时服务器1票数一票，不够半数以上（3票），选举无法完成，服务器1状态保持为&lt;strong&gt;LOOKING&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;服务器2启动，再发起一次选举。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;服务器1和2分别投自己一票，此时服务器1发现服务器2的id比自己大，更改选票投给服务器2。此时服务器1票数0票，服务器2票数2票，不够半数以上（3票），选举无法完成。服务器1，2状态保持&lt;strong&gt;LOOKING&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;服务器3启动，发起一次选举。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;与上面过程一样，服务器1和2先投自己一票，然后因为服务器3id最大，两者更改选票投给为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数（3票），服务器3当选&lt;strong&gt;Leader&lt;/strong&gt;。服务器1，2更改状态为&lt;strong&gt;FOLLOWING&lt;/strong&gt;，服务器3更改状态为&lt;strong&gt;LEADING&lt;/strong&gt;；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;服务器4启动，发起一次选举。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;此时服务器1、2、3已经不是&lt;strong&gt;LOOKING&lt;/strong&gt;状态，不会更改选票信息，交换选票信息结果。服务器3为3票，服务器4为1票。此时服务器4服从多数，更改选票信息为服务器3，服务器4并更改状态为&lt;strong&gt;FOLLOWING&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;服务器5启动，发起一次选举&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;同4一样投票给3，此时服务器3一共5票，服务器5为0票。服务器5并更改状态为&lt;strong&gt;FOLLOWING&lt;/strong&gt;；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;最终&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Leader&lt;/strong&gt;是服务器3，状态为&lt;strong&gt;LEADING&lt;/strong&gt;。其余服务器是&lt;strong&gt;Follower&lt;/strong&gt;，状态为&lt;strong&gt;FOLLOWING&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;322-运行时leader选举&#34;&gt;3.2.2 运行时Leader选举&lt;/h5&gt;
&lt;p&gt;运行时候如果Master节点崩溃了会走恢复模式，新Leader选出前会暂停对外服务，大致可以分为四个阶段  &lt;code&gt;选举&lt;/code&gt;、&lt;code&gt;发现&lt;/code&gt;、&lt;code&gt;同步&lt;/code&gt;、&lt;code&gt;广播&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/20210519zookeeper/5.png&#34; alt=&#34;chooseLeader&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个Server会发出一个投票，第一次都是投自己，其中投票信息 = (myid，ZXID)&lt;/li&gt;
&lt;li&gt;收集来自各个服务器的投票&lt;/li&gt;
&lt;li&gt;处理投票并重新投票，处理逻辑：&lt;strong&gt;优先比较ZXID，然后比较myid&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;统计投票，只要超过半数的机器接收到同样的投票信息，就可以确定leader，注意epoch的增加跟同步。&lt;/li&gt;
&lt;li&gt;改变服务器状态Looking变为Following或Leading。&lt;/li&gt;
&lt;li&gt;当 Follower 链接上 Leader 之后，Leader 服务器会根据自己服务器上最后被提交的 ZXID 和 Follower 上的 ZXID 进行比对，比对结果要么回滚，要么和 Leader 同步，保证集群中各个节点的事务一致。&lt;/li&gt;
&lt;li&gt;集群恢复到广播模式，开始接受客户端的写请求。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;33-脑裂&#34;&gt;3.3 脑裂&lt;/h3&gt;
&lt;p&gt;脑裂问题是集群部署必须考虑的一点，比如在Hadoop跟Spark集群中。而ZAB为解决脑裂问题，要求集群内的节点数量为2N+1。当网络分裂后，始终有一个集群的节点数量&lt;strong&gt;过半数&lt;/strong&gt;，而另一个节点数量小于N+1, 因为选举Leader需要过半数的节点同意，所以我们可以得出如下结论：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有了过半机制，对于一个Zookeeper集群，要么没有Leader，要没只有1个Leader，这样就避免了脑裂问题&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;4-zab-of-consistence&#34;&gt;4. ZAB of Consistence&lt;/h2&gt;
&lt;p&gt;建议先看下  &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI4NjI1OTI4Nw==&amp;amp;mid=2247485515&amp;amp;idx=1&amp;amp;sn=60763ddda77928943bfd3d57e0c9256e&amp;amp;scene=21#wechat_redirect&#34;&gt;浅谈大数据中的2PC、3PC、Paxos、Raft、ZAB&lt;/a&gt; ，不然可能看的吃力。&lt;/p&gt;
&lt;h3 id=&#34;41--zab-协议介绍&#34;&gt;4.1  ZAB 协议介绍&lt;/h3&gt;
&lt;p&gt;ZAB (Zookeeper Atomic Broadcast &lt;strong&gt;原子广播协议&lt;/strong&gt;) 协议是为分布式协调服务ZooKeeper专门设计的一种支持&lt;strong&gt;崩溃恢复&lt;/strong&gt;的一致性协议。基于该协议，ZooKeeper 实现了一种主从模式的系统架构来保持集群中各个副本之间的数据一致性。&lt;/p&gt;
&lt;p&gt;分布式系统中leader负责外部客户端的&lt;strong&gt;写&lt;/strong&gt;请求。follower服务器负责&lt;strong&gt;读跟同步&lt;/strong&gt;。这时需要解决俩问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Leader 服务器是如何把数据更新到所有的Follower的。&lt;/li&gt;
&lt;li&gt;Leader 服务器突然间失效了，集群咋办？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此ZAB协议为了解决上面两个问题而设计了两种工作模式，整个 Zookeeper 就是在这两个模式之间切换：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;原子广播模式：把数据更新到所有的follower。&lt;/li&gt;
&lt;li&gt;崩溃恢复模式：Leader发生崩溃时，如何恢复。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;42-原子广播模式&#34;&gt;4.2 原子广播模式&lt;/h3&gt;
&lt;p&gt;你可以认为消息广播机制是简化版的 &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI4NjI1OTI4Nw==&amp;amp;mid=2247485515&amp;amp;idx=1&amp;amp;sn=60763ddda77928943bfd3d57e0c9256e&amp;amp;scene=21#wechat_redirect&#34;&gt;2PC协议&lt;/a&gt;，就是通过如下的机制&lt;strong&gt;保证事务的顺序一致性&lt;/strong&gt;的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;leader&lt;/strong&gt;从客户端收到一个写请求后生成一个新的事务并为这个事务生成一个唯一的&lt;code&gt;ZXID&lt;/code&gt;，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;leader&lt;/strong&gt;将将带有 &lt;strong&gt;zxid&lt;/strong&gt; 的消息作为一个提案(&lt;strong&gt;proposal&lt;/strong&gt;)分发给所有 &lt;strong&gt;FIFO&lt;/strong&gt;队列。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FIFO&lt;/strong&gt;队列取出队头&lt;strong&gt;proposal&lt;/strong&gt;给&lt;strong&gt;follower&lt;/strong&gt;节点。&lt;/li&gt;
&lt;li&gt;当 &lt;strong&gt;follower&lt;/strong&gt; 接收到 &lt;strong&gt;proposal&lt;/strong&gt;，先将 &lt;strong&gt;proposal&lt;/strong&gt; 写到硬盘，写硬盘成功后再向 &lt;strong&gt;leader&lt;/strong&gt; 回一个 &lt;strong&gt;ACK&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FIFO&lt;/strong&gt;队列把ACK返回给&lt;strong&gt;Leader&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;当&lt;strong&gt;leader&lt;/strong&gt;收到超过一半以上的&lt;strong&gt;follower&lt;/strong&gt;的&lt;strong&gt;ack&lt;/strong&gt;消息，&lt;strong&gt;leader&lt;/strong&gt;会进行&lt;strong&gt;commit&lt;/strong&gt;请求，然后再给&lt;strong&gt;FIFO&lt;/strong&gt;发送&lt;strong&gt;commit&lt;/strong&gt;请求。&lt;/li&gt;
&lt;li&gt;当&lt;strong&gt;follower&lt;/strong&gt;收到&lt;strong&gt;commit&lt;/strong&gt;请求时，会判断该事务的&lt;strong&gt;ZXID&lt;/strong&gt;是不是比历史队列中的任何事务的&lt;strong&gt;ZXID&lt;/strong&gt;都小，如果是则提交，如果不是则等待比它更小的事务的&lt;strong&gt;commit&lt;/strong&gt;(保证顺序性)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;43-崩溃恢复&#34;&gt;4.3 崩溃恢复&lt;/h3&gt;
&lt;p&gt;消息广播过程中，Leader 崩溃了还能保证数据一致吗？当 &lt;strong&gt;Leader&lt;/strong&gt; 崩溃会进入崩溃恢复模式。其实主要是对如下两种情况的处理。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Leader&lt;/strong&gt; 在复制数据给所有 &lt;strong&gt;Follwer&lt;/strong&gt; 之后崩溃，咋搞？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leader&lt;/strong&gt; 在收到 Ack 并提交了自己，同时发送了部分 &lt;strong&gt;commit&lt;/strong&gt; 出去之后崩溃咋办？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;针对此问题，ZAB 定义了 2 个原则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ZAB 协议确保&lt;code&gt;执行&lt;/code&gt;那些已经在 Leader 提交的事务最终会被所有服务器提交。&lt;/li&gt;
&lt;li&gt;ZAB 协议确保&lt;code&gt;丢弃&lt;/code&gt;那些只在 Leader 提出/复制，但没有提交的事务。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;至于如何实现&lt;strong&gt;确保提交已经被 Leader 提交的事务，同时丢弃已经被跳过的事务&lt;/strong&gt;呢？关键点就是依赖上面说到过的 &lt;strong&gt;ZXID&lt;/strong&gt;了。&lt;/p&gt;
&lt;h3 id=&#34;44-zab-特性&#34;&gt;4.4 ZAB 特性&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;一致性保证&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;可靠提交(Reliable delivery) ：如果一个事务 A 被一个server提交(committed)了，那么它最终一定会被所有的server提交&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;全局有序(Total order)&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;假设有A、B两个事务，有一台server先执行A再执行B，那么可以保证所有server上A始终都被在B之前执行&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;因果有序(Causal order)&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;如果发送者在事务A提交之后再发送B,那么B必将在A之后执行&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;高可用性&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;只要大多数（法定数量）节点启动，系统就行正常运行&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;可恢复性&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;当节点下线后重启，它必须保证能恢复到当前正在执行的事务&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;45-zab-和-paxos-对比&#34;&gt;4.5 ZAB 和 Paxos 对比&lt;/h3&gt;
&lt;p&gt;相同点：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;两者都存在一个类似于 Leader 进程的角色，由其负责协调多个 Follower 进程的运行.&lt;/li&gt;
&lt;li&gt;Leader 进程都会等待超过半数的 Follower 做出正确的反馈后，才会将一个提案进行提交.&lt;/li&gt;
&lt;li&gt;ZAB 协议中，每个 Proposal 中都包含一个 epoch 值来代表当前的 Leader周期，Paxos 中名字为 Ballot&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;不同点：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ZAB 用来构建高可用的&lt;strong&gt;分布式数据主备系统&lt;/strong&gt;（Zookeeper），Paxos 是用来构建&lt;strong&gt;分布式一致性状态机系统&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;5-zookeeper-零散知识&#34;&gt;5. ZooKeeper 零散知识&lt;/h2&gt;
&lt;h3 id=&#34;51-常见指令&#34;&gt;5.1 常见指令&lt;/h3&gt;
&lt;p&gt;Zookeeper 有三种部署模式：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;单机部署：一台机器上运行。&lt;/li&gt;
&lt;li&gt;集群部署：多台机器运行。&lt;/li&gt;
&lt;li&gt;伪集群部署：一台机器启动多个 Zookeeper 实例运行。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;部署完毕后常见指令如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;命令基本语法&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;功能描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;help&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;显示所有操作命令&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;ls path [watch]&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;显示所有操作命令&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;ls path [watch]&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;查看当前节点数据并能看到更新次数等数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;create&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;普通创建， -s  含有序列， -e  临时（重启或者超时消失）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;get path [watch]&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;获得节点的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;set&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;设置节点的具体值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;stat&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;查看节点状态&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;delete&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;删除节点&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;rmr&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;递归删除节点&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;52-zookeeper客户端&#34;&gt;5.2 Zookeeper客户端&lt;/h3&gt;
&lt;h5 id=&#34;521-zookeeper原生客户端&#34;&gt;5.2.1. Zookeeper原生客户端&lt;/h5&gt;
&lt;p&gt;Zookeeper客户端是异步的哦！需要引入CountDownLatch 来确保连接好了再做下面操作。Zookeeper原生api是不支持迭代式的创建跟删除路径的，具有如下弊端。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;会话的连接是异步的；必须用到回调函数 。&lt;/li&gt;
&lt;li&gt;Watch需要重复注册：看一次watch注册一次 。&lt;/li&gt;
&lt;li&gt;Session重连机制：有时session断开还需要重连接。&lt;/li&gt;
&lt;li&gt;开发复杂性较高：开发相对来说比较琐碎。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;522-zkclient&#34;&gt;5.2.2. ZkClient&lt;/h5&gt;
&lt;p&gt;开源的zk客户端，在原生API基础上封装，是一个更易于使用的zookeeper客户端，做了如下优化。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;优化一 、在session loss和session expire时自动创建新的ZooKeeper实例进行重连。优化二、 将一次性watcher包装为持久watcher。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&#34;523-curator&#34;&gt;5.2.3. Curator&lt;/h5&gt;
&lt;p&gt;开源的zk客户端，在原生API基础上封装，apache顶级项目。是Netflix公司开源的一套Zookeeper客户端框架。了解过Zookeeper原生API都会清楚其复杂度。Curator帮助我们在其基础上进行封装、实现一些开发细节，包括接连重连、反复注册Watcher和NodeExistsException等。目前已经作为Apache的顶级项目出现，是最流行的Zookeeper客户端之一。&lt;/p&gt;
&lt;h5 id=&#34;524-zookeeper图形化客户端工具&#34;&gt;5.2.4. Zookeeper图形化客户端工具&lt;/h5&gt;
&lt;p&gt;ZooInspector工具&lt;/p&gt;
&lt;h3 id=&#34;53-acl-权限控制机制&#34;&gt;5.3 ACL 权限控制机制&lt;/h3&gt;
&lt;p&gt;ACL全称为Access Control List 即访问控制列表，用于控制资源的访问权限。zookeeper利用ACL策略控制节点的访问权限，如节点数据读写、节点创建、节点删除、读取子节点列表、设置节点权限等。&lt;/p&gt;
&lt;h3 id=&#34;54-zookeeper使用注意事项&#34;&gt;5.4 Zookeeper使用注意事项&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;集群中机器的数量并不是越多越好，一个写操作需要半数以上的节点ack，所以集群节点数越多，整个集群可以抗挂点的节点数越多(越可靠)，但是吞吐量越差。集群的数量必须为奇数。&lt;/li&gt;
&lt;li&gt;zk是基于内存进行读写操作的，有时候会进行消息广播，因此不建议在节点存取容量比较大的数据。&lt;/li&gt;
&lt;li&gt;dataDir目录、dataLogDir两个目录会随着时间推移变得庞大，容易造成硬盘满了。建议自己编写或使用自带的脚本保留最新的n个文件。&lt;/li&gt;
&lt;li&gt;默认最大连接数 默认为60，配置maxClientCnxns参数，配置单个客户端机器创建的最大连接数。&lt;/li&gt;
&lt;/ol&gt;
        
      </description>
    </item>
    
    <item>
      <title>KAFKA和消息队列: Kafka &amp; Message Queue</title>
      <link>https://Jerrysmd.github.io/post/20210427kafka/</link>
      <pubDate>Tue, 27 Apr 2021 14:21:19 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210427kafka/</guid>
      <description>
        
          &lt;p&gt;Apache Kafka aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds. Kafka can connect to external systems (for data import/export) via Kafka Connect and provides Kafka Streams, a Java stream processing library. Kafka uses a binary TCP-based protocol that is optimized for efficiency and relies on a &amp;quot;message set&amp;quot; abstraction that naturally groups messages together to reduce the overhead of the network roundtrip. This &amp;quot;leads to larger network packets, larger sequential disk operations, contiguous memory blocks [...] which allows Kafka to turn a bursty stream of random message writes into linear writes.&amp;quot;&lt;/p&gt;
&lt;h2 id=&#34;message-queue&#34;&gt;Message queue&lt;/h2&gt;
&lt;h3 id=&#34;1-why&#34;&gt;1. Why&lt;/h3&gt;
&lt;p&gt;为什么使用消息队列？&lt;/p&gt;
&lt;p&gt;从系统之间有通信需求开始，就自然产生了消息队列。&lt;/p&gt;
&lt;p&gt;在计算机科学中，消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的资料，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在队列中，直到接收者取回它。&lt;/p&gt;
&lt;h3 id=&#34;2-feature&#34;&gt;2. Feature&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;解耦：&lt;/p&gt;
&lt;p&gt;允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;冗余：&lt;/p&gt;
&lt;p&gt;消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;扩展性：&lt;/p&gt;
&lt;p&gt;因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;灵活性 &amp;amp; 峰值处理能力：&lt;/p&gt;
&lt;p&gt;在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可恢复性：&lt;/p&gt;
&lt;p&gt;系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;顺序保证：&lt;/p&gt;
&lt;p&gt;在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。（Kafka 保证一个 Partition 内的消息的有序性）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缓冲：&lt;/p&gt;
&lt;p&gt;有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;异步通信：&lt;/p&gt;
&lt;p&gt;很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-usage&#34;&gt;3. Usage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;服务解耦：&lt;/p&gt;
&lt;p&gt;下游系统可能只需要当前系统的一个子集，应对不断增加变化的下游系统，当前系统不停地修改调试与这些下游系统的接口，系统间耦合过于紧密。引入消息队列后，当前系统变化时发送一条消息到消息队列的一个主题中，所有下游系统都订阅主题，这样每个下游系统都可以获得一份实时完整的订单数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;异步处理：&lt;/p&gt;
&lt;p&gt;以秒杀为例：风险控制-&amp;gt;库存锁定-&amp;gt;生成订单-&amp;gt;短信通知-&amp;gt;更新统计数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/kafkaAsyn.webp&#34; alt=&#34;kafkaAsyn&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;限流削峰/流量控制&lt;/p&gt;
&lt;p&gt;一个设计健壮的程序有自我保护的能力，也就是说，它应该可以在海量的请求下，还能在自身能力范围内尽可能多地处理请求，拒绝处理不了的请求并且保证自身运行正常。使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-realize&#34;&gt;4. Realize&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;点对点：&lt;/p&gt;
&lt;p&gt;系统 A 发送的消息只能被系统 B 接收，其他任何系统都不能读取 A 发送的消息。&lt;/p&gt;
&lt;p&gt;日常生活的例子比如电话客服就属于这种模型：&lt;/p&gt;
&lt;p&gt;同一个客户呼入电话只能被一位客服人员处理，第二个客服人员不能为该客户服务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/kafkaP2p.webp&#34; alt=&#34;kafkaP2p&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;发布/订阅模型&lt;/p&gt;
&lt;p&gt;这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。&lt;/p&gt;
&lt;p&gt;生活中的报纸订阅就是一种典型的发布 / 订阅模型。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/kafkaSub.webp&#34; alt=&#34;kafkaSub&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;kafka&#34;&gt;Kafka&lt;/h2&gt;
&lt;h3 id=&#34;1-intro&#34;&gt;1. Intro&lt;/h3&gt;
&lt;p&gt;kafka是一个分布式流处理平台。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;类似一个消息系统，读写流式的数据&lt;/li&gt;
&lt;li&gt;编写可扩展的流处理应用程序，用于实时事件响应的场景&lt;/li&gt;
&lt;li&gt;安全的将流式的数据存储在一个分布式，有副本备份，容错的集群&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2--history&#34;&gt;2.  History&lt;/h3&gt;
&lt;p&gt;Kafka从何而来?我们为什么要开发Kafka? Kafka到底是什么?
Kafka 最初是 LinkedIn 的一个内部基础设施系统。我们发现虽然有很多数据库和系统可以用来存储数据，但在我们的架构里，&lt;strong&gt;刚好缺一个可以帮助处理持续数据流的组件&lt;/strong&gt;。在开发Kafka之前，我们实验了各种现成的解决方案，&lt;strong&gt;从消息系统到日志聚合系统，再到ETL工具，它们都无法满足我们的需求。&lt;/strong&gt;
最后，我们决定从头开发一个系统。&lt;strong&gt;我们不想只是开发一个能够存储数据的系统&lt;/strong&gt;，比如传统的关系型数据库、键值存储引擎、搜索引擎或缓存系统，&lt;strong&gt;我们希望能够把数据看成是持续变化和不断增长的流&lt;/strong&gt;，并基于这样的想法构建出一个数据系统。事实上，是一个数据架构。
这个想法实现后比我们最初预想的适用性更广。Kafka 一开始被用在社交网络的实时应用和数据流当中，而现在已经成为下一代数据架构的基础。大型零售商正在基于持续数据流改造他们的基础业务流程，汽车公司正在从互联网汽车那里收集和处理实时数据流，银行也在重新思考基于 Kafka 改造他们的基础。&lt;/p&gt;
&lt;p&gt;它可以用于两大类别的应用:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构造实时流数据管道，它可以在系统或应用之间可靠地获取数据。(相当于message queue)&lt;/li&gt;
&lt;li&gt;构建实时流式应用程序，对这些流数据进行转换或者影响。(就是流处理，通过kafka stream topic和topic之间内部进行变化)&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;版本号&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.7&lt;/td&gt;
&lt;td&gt;上古版本，提供了最基础的消息队列功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;引入了&lt;strong&gt;副本机制&lt;/strong&gt;，成为了一个真正意义上完备的分布式高可靠消息队列解决方案&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.8.2&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;新版本 Producer API&lt;/strong&gt;，即需要指定 Broker 地址的 Producer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;td&gt;增加了基础的安全认证 / 权限，Java 重写了新版本消费者 API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.10.0.0&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;引入了 Kafka Streams&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.11.0.0&lt;/td&gt;
&lt;td&gt;提供幂等性 Producer API 以及事务（Transaction） API，对 Kafka 消息格式做了重构。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;Kafka Streams 的各种改进&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.0&lt;/td&gt;
&lt;td&gt;Kafka Streams 的各种改进&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;3-item&#34;&gt;3. Item&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;消息：Record。这里的消息就是指 Kafka 处理的主要对象。&lt;/li&gt;
&lt;li&gt;服务：&lt;strong&gt;Broker&lt;/strong&gt;。一个 Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。&lt;/li&gt;
&lt;li&gt;主题：&lt;strong&gt;Topic&lt;/strong&gt;。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。&lt;/li&gt;
&lt;li&gt;分区：&lt;strong&gt;Partition&lt;/strong&gt;。一个有序不变的消息序列。每个主题下可以有多个分区。&lt;/li&gt;
&lt;li&gt;消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。&lt;/li&gt;
&lt;li&gt;副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。&lt;/li&gt;
&lt;li&gt;生产者：&lt;strong&gt;Producer&lt;/strong&gt;。向主题发布新消息的应用程序。&lt;/li&gt;
&lt;li&gt;消费者：&lt;strong&gt;Consumer&lt;/strong&gt;。从主题订阅新消息的应用程序。&lt;/li&gt;
&lt;li&gt;消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。&lt;/li&gt;
&lt;li&gt;消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。&lt;/li&gt;
&lt;li&gt;重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/kafkaItem.png&#34; alt=&#34;kafkaItem&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;4-topic&#34;&gt;4. Topic&lt;/h3&gt;
&lt;p&gt;日志&lt;/p&gt;
&lt;p&gt;日志可能是一种最简单的不能再简单的存储抽象，只能追加、按照时间完全有序（totally-ordered）的记录序列。日志看起来的样子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/kafkaLog.png&#34; alt=&#34;kafkaLog&#34;&gt;&lt;/p&gt;
&lt;p&gt;在日志的末尾添加记录，读取日志记录则从左到右。每一条记录都指定了一个唯一的顺序的日志记录编号。&lt;/p&gt;
&lt;p&gt;日志记录的次序（ordering）定义了『时间』概念，因为位于左边的日志记录表示比右边的要早。日志记录编号可以看作是这条日志记录的『时间戳』。把次序直接看成是时间概念，刚开始你会觉得有点怪异，但是这样的做法有个便利的性质：解耦了 时间 和 任一特定的物理时钟（physical clock）。引入分布式系统后，这会成为一个必不可少的性质。&lt;/p&gt;
&lt;p&gt;日志 和 文件或数据表（table）并没有什么大的不同。文件是一系列字节，表是由一系列记录组成，而日志实际上只是一种按照时间顺序存储记录的数据表或文件。&lt;/p&gt;
&lt;p&gt;对于每一个topic， Kafka集群都会维持一个分区日志，如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/kafkaPartitionLog.png&#34; alt=&#34;kafkaPartitionLog&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实操&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;启动zk&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; /usr/local/kara/kafka_2.13-2.6.0/bin
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;zookeeper-server-start.sh ../config/zookeeper.properties
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;启动kafka服务器&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;kafka-server-start.sh ../config/server.properties
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;创建topic，4个分区，一个副本&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; --partitions &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt; --topic partition_test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;发送一些消息&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;kafka-console-producer.sh --broker-list localhost:9092 --topic partition_test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;启动一个consumer&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic partition_test --from-beginning
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;分区&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;partition存储分布&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为&lt;strong&gt;topic名称+有序序号&lt;/strong&gt;，第一个partiton序号从0开始，序号最大值为partitions数量减1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;partition文件存储&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。&lt;/p&gt;
&lt;p&gt;2.每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;segment文件存储&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，分别表示为segment索引文件、数据文件.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;segment中的消息message物理结构字段说明&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;关键字&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;解释说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;8 byte offset&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4 byte message size&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;message大小&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4 byte CRC32&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;用crc32校验message&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 byte “magic”&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;表示本次发布Kafka服务程序协议版本号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 byte “attributes”&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;表示为独立版本、或标识压缩类型、或编码类型。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4 byte key length&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;表示key的长度,当key为-1时，K byte key字段不填&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;K byte key&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;可选&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;value bytes payload&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;表示实际消息数据。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;文件系统&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kafka 对消息的存储和缓存严重依赖于文件系统。人们对于“磁盘速度慢”具有普遍印象，事实上，磁盘的速度比人们预期的要慢的多，也快得多，这取决于人们使用磁盘的方式。&lt;/p&gt;
&lt;p&gt;使用6个7200rpm、SATA接口、RAID-5的磁盘阵列在JBOD配置下的顺序写入的性能约为600MB/秒，但随机写入的性能仅约为100k/秒，相差6000倍以上。&lt;/p&gt;
&lt;p&gt;线性的读取和写入是磁盘使用模式中最有规律的，并且由操作系统进行了大量的优化。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;read-ahead 是以大的 data block 为单位预先读取数据&lt;/li&gt;
&lt;li&gt;write-behind 是将多个小型的逻辑写合并成一次大型的物理磁盘写入&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于该问题的进一步讨论可以参考 ACM Queue article，他们发现实际上顺序磁盘访问在某些情况下比随机内存访问还要快！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为了弥补这种性能差异，现代操作系统主动将所有空闲内存用作 disk caching（磁盘高速缓存），所有对磁盘的读写操作都会通过这个统一的 cache（ in-process cache）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;即使进程维护了 in-process cache，该数据也可能会被复制到操作系统的 pagecache 中，事实上所有内容都被存储了两份。&lt;/p&gt;
&lt;p&gt;此外，Kafka 建立在 JVM 之上，任何了解 Java 内存使用的人都知道两点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对象的内存开销非常高，通常是所存储的数据的两倍(甚至更多)。&lt;/li&gt;
&lt;li&gt;随着堆中数据的增加，Java 的垃圾回收变得越来越复杂和缓慢。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;kafka选择了一个非常简单的设计：相比于维护尽可能多的 in-memory cache，并且在空间不足的时候匆忙将数据 flush 到文件系统，我们把这个过程倒过来。&lt;strong&gt;所有数据一开始就被写入到文件系统的持久化日志中，而不用在 cache 空间不足的时候 flush 到磁盘&lt;/strong&gt;。实际上，这表明数据被转移到了内核的 pagecache 中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pagecache页面缓存&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Page cache（页面缓存）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Page cache 也叫页缓冲或文件缓冲，是由好几个磁盘块构成，大小通常为4k，在64位系统上为8k，构成的几个磁盘块在物理磁盘上不一定连续，文件的组织单位为一页， 也就是一个page cache大小，文件读取是由外存上不连续的几个磁盘块，到buffer cache，然后组成page cache，然后供给应用程序。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Buffer cache（块缓存）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Buffer cache 也叫块缓冲，是对物理磁盘上的一个磁盘块进行的缓冲，其大小为通常为1k，磁盘块也是磁盘的组织单位。设立buffer cache的目的是为在程序多次访问同一磁盘块时，减少访问时间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Page cache（页面缓存）与Buffer cache（块缓存）的区别&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;磁盘的操作有逻辑级（文件系统）和物理级（磁盘块），这两种Cache就是分别缓存逻辑和物理级数据的。&lt;/p&gt;
&lt;p&gt;我们通过文件系统操作文件，那么文件将被缓存到Page Cache，如果需要刷新文件的时候，Page Cache将交给Buffer Cache去完成，因为Buffer Cache就是缓存磁盘块的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简单说来，page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache，如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Buffer(Buffer Cache)以块形式缓冲了块设备的操作，定时或手动的同步到硬盘，它是为了缓冲写操作然后一次性将很多改动写入硬盘，避免频繁写硬盘，提高写入效率。&lt;/p&gt;
&lt;p&gt;Cache(Page Cache)以页面形式缓存了文件系统的文件，给需要使用的程序读取，它是为了给读操作提供缓冲，避免频繁读硬盘，提高读取效率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;降低时间复杂度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;消息系统使用的持久化数据结构通常是和 BTree 相关联的消费者队列或者其他用于存储消息源数据的通用随机访问数据结构。&lt;strong&gt;BTree 的操作复杂度是 O(log N)&lt;/strong&gt;，通常我们认为 O(log N) 基本等同于常数时间，但这条在磁盘操作中不成立。&lt;/p&gt;
&lt;p&gt;存储系统将非常快的cache操作和非常慢的物理磁盘操作混合在一起，当数据随着 fixed cache 增加时，可以看到树的性能通常是非线性的——比如数据翻倍时性能下降不只两倍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kafka选择把持久化队列建立在简单的读取和向文件后追加两种操作之上&lt;/strong&gt;，这和日志解决方案相同。&lt;strong&gt;这种架构的优点在于所有的操作复杂度都是O(1)，而且读操作不会阻塞写操作，读操作之间也不会互相影响。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在不产生任何性能损失的情况下能够访问几乎无限的硬盘空间，Kafka 可以让消息保留相对较长的一段时间(比如一周)，而不是试图在被消费后立即删除。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;降低大量小型IO操作的影响&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;小型的 I/O 操作发生在客户端和服务端之间以及服务端自身的持久化操作中。&lt;/p&gt;
&lt;p&gt;为了避免这种情况，kafka的协议是建立在一个 “消息块” 的抽象基础上，合理将消息分组。将多个消息打包成一组，而不是每次发送一条消息，从而使整组消息分担网络中往返的开销。&lt;/p&gt;
&lt;p&gt;这个简单的优化对速度有着数量级的提升。批处理允许更大的网络数据包，更大的顺序读写磁盘操作，连续的内存块等等，所有这些都使 KafKa 将随机流消息顺序写入到磁盘， 再由 consumers 进行消费。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;零拷贝&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;字节拷贝是低效率的操作，在消息量少的时候没啥问题，但是在高负载的情况下，影响就不容忽视。为了避免这种情况，kafka使用 producer ，broker 和 consumer 都共享的标准化的二进制消息格式，这样数据块不用修改就能在他们之间传递。&lt;/p&gt;
&lt;p&gt;保持这种通用格式可以&lt;strong&gt;对一些很重要的操作进行优化&lt;/strong&gt;: 持久化&lt;strong&gt;日志块的网络传输&lt;/strong&gt;。现代的unix 操作系统提供了一个高度优化的编码方式，用于将数据从 pagecache 转移到 socket 网络连接中；在 Linux 中系统调用 sendfile 做到这一点。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;传统IO &lt;strong&gt;(4次上下文切换4次拷贝)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假如将磁盘上的文件读取出来，然后通过网络协议发送给客户端。&lt;/p&gt;
&lt;p&gt;一般需要两个系统调用，&lt;strong&gt;但是一共4次上下文切换，4次拷贝&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;read(file, tmp_buf, len);
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;write(socket, tmp_buf, len);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;mmap(&lt;strong&gt;4次上下文切换3次拷贝&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;mmap()系统调用函数会直接把内核缓冲区里的数据「&lt;strong&gt;映射&lt;/strong&gt;」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作，它替换了read()系统调用函数。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;buf = mmap(file, len);
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;write(sockfd, buf, len);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;sendfile（&lt;strong&gt;2次上下文切换3次拷贝&lt;/strong&gt;）&lt;/p&gt;
&lt;p&gt;Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 sendfile()&lt;/p&gt;
&lt;p&gt;首先，它可以替代前面的 read()和 write()这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。&lt;/p&gt;
&lt;p&gt;其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;#include &amp;lt;sys/socket.h&amp;gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;零拷贝（2次上下文切换2次拷贝）&lt;/p&gt;
&lt;p&gt;Linux 内核 2.4 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， sendfile() 系统调用的过程发生了点变化，具体过程如下：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；&lt;/li&gt;
&lt;li&gt;第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;kafka高效文件存储设计特点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。&lt;/li&gt;
&lt;li&gt;通过索引信息可以快速定位message和确定response的最大大小。&lt;/li&gt;
&lt;li&gt;通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。&lt;/li&gt;
&lt;li&gt;通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。&lt;/li&gt;
&lt;/ul&gt;
        
      </description>
    </item>
    
    <item>
      <title>Spark 简介: Spark Guide, Part Ⅰ</title>
      <link>https://Jerrysmd.github.io/post/20210331spark/</link>
      <pubDate>Wed, 31 Mar 2021 10:28:47 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210331spark/</guid>
      <description>
        
          &lt;p&gt;Apache Spark has its architectural foundation in the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. The Dataframe API was released as an abstraction on top of the RDD, followed by the Dataset API.&lt;/p&gt;
&lt;h2 id=&#34;spark-introduction&#34;&gt;Spark Introduction&lt;/h2&gt;
&lt;h3 id=&#34;1-spark-component&#34;&gt;1 Spark Component&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Spark提供了批处理（RDDs），结构化查询（DataFrame），流计算（SparkStreaming），机器学习（MLib），图计算（GraphX）等组件&lt;/li&gt;
&lt;li&gt;这些组件均是依托于通用的计算引擎RDDs而构建出，所以spark-core的RDDs是整个Spark的基础&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/sparkStructure.png&#34; alt=&#34;sparkStructure&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-spark--hadoop&#34;&gt;2 Spark &amp;amp; Hadoop&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Hadoop&lt;/th&gt;
&lt;th&gt;Spark&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;类型&lt;/td&gt;
&lt;td&gt;基础平台，包含计算，存储，调度&lt;/td&gt;
&lt;td&gt;分布式计算工具（主要代替Hadoop的计算功能）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;场景&lt;/td&gt;
&lt;td&gt;大规模数据集上的批处理&lt;/td&gt;
&lt;td&gt;迭代计算，交互式计算，流计算&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;延迟&lt;/td&gt;
&lt;td&gt;大&lt;/td&gt;
&lt;td&gt;小&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;易用性&lt;/td&gt;
&lt;td&gt;API较为底层，算法适应性差&lt;/td&gt;
&lt;td&gt;API较为顶层，方便使用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;价格&lt;/td&gt;
&lt;td&gt;性能要求低，便宜&lt;/td&gt;
&lt;td&gt;对内存要求高，相对较贵&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;spark-cluster&#34;&gt;Spark Cluster&lt;/h2&gt;
&lt;h3 id=&#34;1-cluster--relation&#34;&gt;1 Cluster  relation&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/clusterManager.png&#34; alt=&#34;clusterManager&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Driver：该进程调用Spark程序的main方法，并且启动SparkContext&lt;/li&gt;
&lt;li&gt;Cluster Manager：该进程负责和外部集群工具打交道，申请或释放集群资源&lt;/li&gt;
&lt;li&gt;Worker：该进程是一个守护进程，负责启动和管理Executor&lt;/li&gt;
&lt;li&gt;Executor：该进程是一个JVM虚拟机，负责运行Spark Task&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;运行一个Spark程序大致经历如下几个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;启动Driver，创建SparkContext&lt;/li&gt;
&lt;li&gt;Client提交程序给Drive，Drive向Cluster Manager申请集群资源&lt;/li&gt;
&lt;li&gt;资源申请完毕，在Worker中启动Executor&lt;/li&gt;
&lt;li&gt;Driver将程序转化为Tasks，分发给Executor执行&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;2-build-cluster&#34;&gt;2 Build Cluster&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Download Spark&lt;/li&gt;
&lt;li&gt;Upload&lt;/li&gt;
&lt;li&gt;Config&lt;/li&gt;
&lt;li&gt;HistoryServer&lt;/li&gt;
&lt;li&gt;Distribute:  scp -r spark node02: $PWD&lt;/li&gt;
&lt;li&gt;Start&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-high-availability&#34;&gt;3 High Availability&lt;/h3&gt;
&lt;p&gt;对于 Spark Standalone 集群来说，当Worker调度出现问题时，会自动的弹性容错，将出错的Task调度到其他Worker执行。&lt;/p&gt;
&lt;p&gt;但对于Master来说，是会出现单点失败的，为了避免可能出现的单点失败问题，Spark提供了两种方式满足高可用&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用Zookeeper实现Master的主备切换(Zookeeper是一个分布式强一致性的协调服务，Zookeeper最基本的一个保证是：如果多个节点同时创建一个ZNode)只有一个能够成功创建，这个做法的本质使用的是Zookeeper的ZAB协议，能够在分布式环境下达成一致。&lt;/li&gt;
&lt;li&gt;使用文件系统做主备切换&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;running-process&#34;&gt;Running Process&lt;/h2&gt;
&lt;h3 id=&#34;1-spark-shell-run&#34;&gt;1 Spark-Shell Run&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;textFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/data/wordcount.txt&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;//Hadoop默认读取hdfs路径：hdfs:///data/wordcount.txt
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rddflatMap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd3&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd4&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rdd4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/sparkDemoRunProcess.png&#34; alt=&#34;sparkDemoRunProcess&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-local-idea-run&#34;&gt;2 Local IDEA Run&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;Arrary&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 创建SparkContext
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkConf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setMaster&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;local[6]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setAppName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;word_count&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//2. 加载文件
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//	准备文件
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//	2.读取文件
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;testFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;dataset/wordcount.txt&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//3. 处理
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//	拆分为多个单词
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rddflatMap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//	2.把每个单词指定一个词频
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd3&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//	3.聚合
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd4&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt;19&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//4.得到结果
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;21&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3--submit-run&#34;&gt;3  Submit Run&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;修改代码
&lt;ol&gt;
&lt;li&gt;去掉master设置，并修改文件路径&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Maven打包上传&lt;/li&gt;
&lt;li&gt;在集群中运行&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;bin/spark -submit --class cn.demo.spark.rdd.WordCount --master spark://node01:7077 ~/original -spark-0.0.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;rdd&#34;&gt;RDD&lt;/h2&gt;
&lt;h3 id=&#34;1-cause-of-creation&#34;&gt;1 Cause of creation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;在RDD出现之前，MapReduce是比较主流的&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;但多个MapReduce任务之间没有基于内存的数据共享方式，只能通过磁盘来进行共享，这种方式明显比较低效。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RDD如何解决迭代计算非常低效的问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在Spark中，最终Job3从逻辑上的计算过程是：Job3 = (Job1.map).filter，整个过程是共享内存的，而不需要中间结果存放在可靠的分布式文件系统中。&lt;/p&gt;
&lt;h3 id=&#34;2-resilient-distributed-datasets&#34;&gt;2 Resilient Distributed Datasets&lt;/h3&gt;
&lt;p&gt;分布式&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;RDD支持分区，可以运行在集群中&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;弹性&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;RDD支持高效的容错&lt;/li&gt;
&lt;li&gt;RDD中的数据即可以缓存在内存中，也可以缓存在磁盘中，也可以缓存在外部存储中&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;数据集&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;RDD可以不保存具体数据，只保留创建自己的必备信息，例如依赖和计算函数&lt;/li&gt;
&lt;li&gt;RDD也可以缓存起来，相当于存储具体数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;3-feature&#34;&gt;3 Feature&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;RDD是数据集&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;RDD不仅是数据集，也是编程模型&lt;/p&gt;
&lt;p&gt;RDD的算子大致分为两类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Transformation转化操作，例如：map、flatMap、filter等&lt;/li&gt;
&lt;li&gt;Action动作操作，例如：reduce、collect、show等&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;RDD是编程模型&lt;/li&gt;
&lt;li&gt;RDD相互之间有依赖关系&lt;/li&gt;
&lt;li&gt;RDD是可以分区的&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RDD是只读的&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;RDD需要容错，可以惰性求值，可以移动计算，所以很难支持修改，显著降低问题的复杂度。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/sparkRdd.png&#34; alt=&#34;sparkRdd&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;4-sparkcontext&#34;&gt;4 sparkContext&lt;/h3&gt;
&lt;p&gt;SparkContext是spark功能的主要入口。其代表与spark集群的连接，能够用来在集群上创建RDD、累加器、广播变量。每个JVM里只能存在一个处于激活状态的SparkContext，在创建新的SparkContext之前必须调用stop()来关闭之前的SparkContext。&lt;/p&gt;
&lt;p&gt;每一个Spark应用都是一个SparkContext实例，可以理解为一个SparkContext就是一个spark application的生命周期，一旦SparkContext创建之后，就可以用这个SparkContext来创建RDD、累加器、广播变量，并且可以通过SparkContext访问Spark的服务，运行任务。spark context设置内部服务，并建立与spark执行环境的连接。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sparkContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//  Spark Context 编写
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 		创建SparkConf
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkConf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setMaster&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;local[6]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setAppName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;spark_context&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//		2.创建SparkContext
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//SparkContext身为大入口API，应该能够创建RDD，并且设置参数，设置Jar包
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//sc...
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//2. 关闭SparkContext，释放集群资源
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;5-creation-way&#34;&gt;5 Creation Way&lt;/h3&gt;
&lt;p&gt;三种RDD的创建方式&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;通过本地集合创建RDD&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rddCreationLocal&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkConf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setMaster&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;local[6]&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setAppName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;spark_context&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SparkContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hello1&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Hello2&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Hello3&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;makeRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// parallelize和makeRDD区别：parallelize可以不指定分区数
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;通过外部数据创建RDD&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rddCreationFiles&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;textFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/.../...&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//testFile: 传入* hdfs://   file://   /.../...(这种方式分为在集群还是本地执行，在集群中读的是hdfs，本地读本地文件)
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//2.是否支持分区：支持，在hdfs中由hdfs文件的block决定
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//3.支持什么平台：支持aws和阿里云...
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;3.&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;通过RDD衍生新的RDD&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;19&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rddCreationFromRDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;20&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;21&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//通过在rdd上执行算子操作，会生成新的rdd
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//非原地计算：str.substr 返回新的字符串，非原地计算。字符串不可变，RDD也不可变
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;23&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;RDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;Int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rddmap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;24&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;transformation-operator&#34;&gt;Transformation Operator&lt;/h2&gt;
&lt;h3 id=&#34;map&#34;&gt;map()&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mapTest&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//创建RDD
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//2.执行map操作
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//3.得到结果
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;flatmap&#34;&gt;flatmap()&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;把rdd中的数据转化成数组或集合形式&lt;/li&gt;
&lt;li&gt;把集合展开&lt;/li&gt;
&lt;li&gt;生成了多条数据&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;flatmap是一对多&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flatMapTest&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hello a&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hello b&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hello c&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rddf1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;latMap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;6&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;7&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;reducebykey&#34;&gt;reducebykey()&lt;/h3&gt;
&lt;p&gt;reduceByKey第一步先按照key分组，然后对每一组进行聚合，得到结果。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reduceBykeyTest&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//创建RDD
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hello a&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hello b&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hello c&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//2.处理数据
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flatMap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduceByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//curr是当前的总值，agg是单个item的值
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//3.得到结果
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;//4.关闭sc
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; 
&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;qa&#34;&gt;Q&amp;amp;A&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;数据量过大，如何处理？&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;集群中处理，利用集群多台计算机来并行处理&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;如何放在集群中运行?&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/sparkPutFile2Cluster.png&#34; alt=&#34;sparkPutFile2Cluster&#34;&gt;&lt;/p&gt;
&lt;p&gt;并行计算就是同时使用多个计算资源解决一个问题，有四个要点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解决的问题可以分解为多个可以并发计算的部分&lt;/li&gt;
&lt;li&gt;每个部分可以在不同处理器上被同时执行&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;需要一个共享内存的机制&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;需要一个总体上的协作机制来进行调度&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;如果放在集群中，如何对整个计算任务进行分解？&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://Jerrysmd.github.io/post/picture/sparkFile2Cluster2.png&#34; alt=&#34;sparkFile2Cluster2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于HDFS中的文件，是分为不同的Block&lt;/li&gt;
&lt;li&gt;在进行计算的时候，就可以按照Block来划分，每一个Block对应一个不同的计算单元&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;扩展&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RDD并没有真实的存放数据，数据是从HDFS中读取的，在计算的过程中读取即可&lt;/li&gt;
&lt;li&gt;RDD至少是需要可以&lt;strong&gt;分片&lt;/strong&gt;的，因为HDFS中的文件就是分片的，RDD可以分片也意味着可以并行计算&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;移动数据不如移动计算是一个基础的优化，如何做到？&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;每一个计算单元需要记录其存储单元的位置，尽量调度过去&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;集群中运行，需要多节点配合，出错的概率也更高，出错了怎么办？&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;RDD1-&amp;gt;RDD2-&amp;gt;RDD3这个过程中，RDD2出错了，有两种解决办法&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;缓存RDD2的数据，直接恢复RDD2，类似HDFS的备份机制&lt;/li&gt;
&lt;li&gt;记录RDD2的依赖关系，通过其父级的RDD来恢复RDD2，这种方式会少很多数据的交互和保存&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;如何通过父级RDD恢复？&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;记录RDD2的父亲是RDD1&lt;/li&gt;
&lt;li&gt;记录RDD2的计算函数，例如RDD2 = RDD1.map(...)等计算函数&lt;/li&gt;
&lt;li&gt;通过父级RDD和计算函数来恢复RDD2&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;任务特别复杂，流程特别长，有很多RDD之间有依赖关系，如何优化？&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;上面提到了可以使用依赖关系来进行&lt;strong&gt;容错&lt;/strong&gt;，但是如果依赖关系特别长的时候，这种方式其实也比较低效，这个时候就应该使用另外一种方式，也就是记录数据集的状态&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在Spark中有两个手段可以做到&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;缓存&lt;/li&gt;
&lt;li&gt;Checkpoint&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;map--mappartitions&#34;&gt;map() &amp;amp; mapPartitions()&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;mapPartitions 和 map 算子是一样的，只不过map是针对每一条数据进行转换，mapPartitions针对一整个分区的数据进行转换&lt;/p&gt;
&lt;p&gt;所以&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;map 的 func 参数是单条数据，mapPartitions 的 func 参数是一个集合(一个分区整个所有的数据)&lt;/li&gt;
&lt;li&gt;map 的 func 返回值也是单条数据，mapPartition 的 func 返回值是一个集合&lt;/li&gt;
&lt;li&gt;mapPartitionWithIndex 和 mapPartition 的区别是 func 中多分区数量参数&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;filter&#34;&gt;filter()&lt;/h3&gt;
&lt;p&gt;保留满足条件的元素&lt;/p&gt;
&lt;h3 id=&#34;sample&#34;&gt;sample()&lt;/h3&gt;
&lt;p&gt;filter按照规律过滤，sample则是随机采样&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;withReplacement&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Boolean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;//是否重复取样
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;fraction&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;			&lt;span class=&#34;c1&#34;&gt;//取样比例
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;seed&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Long&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Utils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nextLong&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;RDD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{...}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;mapvalues&#34;&gt;mapValues()&lt;/h3&gt;
&lt;p&gt;mapValue也是map，map作用于全部数据，mapValue作用于value&lt;/p&gt;
&lt;h3 id=&#34;collection-operation&#34;&gt;collection operation&lt;/h3&gt;
&lt;p&gt;交集：rdd1.intersection(rdd2)&lt;/p&gt;
&lt;p&gt;并集：rdd1.union(rdd2)&lt;/p&gt;
&lt;p&gt;差集：rdd1.subract(rdd2)&lt;/p&gt;
&lt;h3 id=&#34;groupbykey&#34;&gt;groupByKey()&lt;/h3&gt;
&lt;p&gt;聚合操作：&lt;/p&gt;
&lt;p&gt;reduceByKey -&amp;gt;按照key分组，然后把每一组数据reduce。reduceByKey在map端combiner能减少IO，一个分区放多个数据。&lt;/p&gt;
&lt;p&gt;groupByKey 运算结果的格式：（k，（value1，value2）），没有减少IO&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parallelize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Seq&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;a&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;a&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)))&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupByKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;combinebykey&#34;&gt;combineByKey()&lt;/h3&gt;
&lt;p&gt;接收三个参数：&lt;/p&gt;
&lt;p&gt;转化数据的函数（初始函数，作用于第一条数据，用于开启整个计算）&lt;/p&gt;
&lt;p&gt;在分区上进行聚合&lt;/p&gt;
&lt;p&gt;把所有的分区的聚合结果聚合为最终结果&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rdd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;combineBykey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;	&lt;span class=&#34;n&#34;&gt;createCombiner&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; 
&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;mergeValue&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;Double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nextValue&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nextValue&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)),&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;mergeCombiners&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;Double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;Int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;Double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;agg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;foldbykey&#34;&gt;foldByKey()&lt;/h3&gt;
&lt;p&gt;功能等同于reduceByKey()，增加了初始值。reduceByKey底层是combineByKey()，foldByKey()底层是aggregateByKey()。&lt;/p&gt;
&lt;h3 id=&#34;aggregatebykey&#34;&gt;aggregateByKey()&lt;/h3&gt;
&lt;h3 id=&#34;join&#34;&gt;join()&lt;/h3&gt;
&lt;p&gt;按照相同的Key进行连接&lt;/p&gt;
&lt;h3 id=&#34;sortby&#34;&gt;sortBy()&lt;/h3&gt;
&lt;p&gt;排序：sortBy()，sortByKey()&lt;/p&gt;
&lt;h3 id=&#34;coalesce&#34;&gt;coalesce()&lt;/h3&gt;
&lt;p&gt;一般涉及到分区操作的算子常见的有两个，repartition和coalesce，都可以调大或者调小分区数量&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;summary&lt;/h3&gt;
&lt;p&gt;所有的转化操作的算子都是惰性的，在执行时候不会调度运行求得结果，而只是生成了对应的RDD&lt;/p&gt;
&lt;p&gt;只有在Action操作的时候，才会真的运行&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>HDFS &amp; NFS</title>
      <link>https://Jerrysmd.github.io/post/20210326hdfsnfs/</link>
      <pubDate>Fri, 26 Mar 2021 11:02:36 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210326hdfsnfs/</guid>
      <description>
        
          &lt;p&gt;The major difference between the two is Replication/Fault Tolerance. HDFS was designed to survive failures. NFS does not have any fault tolerance built in. Other than fault tolerance, HDFS does support multiple replicas of files. This eliminates (or eases) the common bottleneck of many clients accessing a single file. Since files have multiple replicas, on different physical disks, reading performance scales better than NFS.&lt;/p&gt;
&lt;h2 id=&#34;nfs&#34;&gt;NFS&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;NFS (Network&lt;/strong&gt; &lt;strong&gt;File system&lt;/strong&gt;): A protocol developed that allows clients to access files over the network. NFS clients allow files to be accessed as if the files reside on the local machine, even though they reside on the disk of a networked machine.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;NFS&lt;/strong&gt;, the data is stored only on one main system. All the other systems in that network can access the data stored in that as if it was stored in their local system. But the problem with this is that, if the main system goes down, then the data is lost and also, the storage depends on the space available on that system.&lt;/p&gt;
&lt;h2 id=&#34;hdfs&#34;&gt;HDFS&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;HDFS (Hadoop Distributed File System):&lt;/strong&gt; A file system that is distributed amongst many networked computers or nodes. HDFS is fault tolerant because it stores multiple replicas of files on the file system, the default replication level is 3.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;HDFS,&lt;/strong&gt; data is distributed among different systems called datanodes. Here, the storage capacity is comparatively high. &lt;strong&gt;HDFS&lt;/strong&gt; is mainly used to store Big Data and enable fast data transaction.&lt;/p&gt;
&lt;h2 id=&#34;similarities&#34;&gt;Similarities&lt;/h2&gt;
&lt;p&gt;两者的文件系统数据均能够在相关系统内的多台机器上进行数据读取和写入，都是分布式文件系统&lt;/p&gt;
&lt;h2 id=&#34;differences&#34;&gt;Differences&lt;/h2&gt;
&lt;p&gt;NFS是通过RPC通信协议进行数据共享的文件系统，所以NFS必须在运行的同时确保RPC能够正常工作。在不同的文件进行读取和写入时，实际上是对服务端的共享文件地址进行操作，一旦服务端出现问题，那么其他所有的机器无法进行文件读取和写入，并且数据无法找回。所以NFS系统的文件其实并没有备份，并且其服务端没有做高可用处理。&lt;/p&gt;
&lt;p&gt;HDFS是通过数据备份进行的大数据存储文件系统。HDFS有系统备份，并且其namenode有secondnamenode进行备份处理，更加安全可靠。数据在经过多副本存储后，能够抵御各种灾难，只要有一个副本不丢失，数据就不会丢失。所以数据的安全性很高。&lt;/p&gt;
        
      </description>
    </item>
    
    <item>
      <title>Scala 简介: Scala Introduction</title>
      <link>https://Jerrysmd.github.io/post/20210308scalaintroduction/</link>
      <pubDate>Mon, 08 Mar 2021 10:16:17 +0800</pubDate>
      
      <guid>https://Jerrysmd.github.io/post/20210308scalaintroduction/</guid>
      <description>
        
          &lt;p&gt;Scala combines object-oriented and functional programming in one concise, high-level language. Scala&#39;s static types help avoid bugs in complex applications, and its JVM and JavaScript runtimes let you build high-performance systems with easy access to huge ecosystems of libraries.&lt;/p&gt;
&lt;h2 id=&#34;1-repl--scaladoc&#34;&gt;1. REPL &amp;amp; Scaladoc&lt;/h2&gt;
&lt;p&gt;Scala解释器读到一个表达式，对它进行求值，将它打印出来，接着再继续读下一个表达式。这个过程被称做Read-Eval-Print-Loop，即：REPL。
从技术上讲，scala程序并不是一个解释器。实际发生的是，你输入的内容被快速地编译成字节码，然后这段字节码交由Java虚拟机执行。正因为如此，大多数scala程序员更倾向于将它称做“REPL”&lt;/p&gt;
&lt;p&gt;scala api文档，包含了scala所有的api以及使用说明，class、object、trait、function、method、implicit等&lt;/p&gt;
&lt;p&gt;为什么要查阅Scaladoc：如果只是写一些普通的Scala程序基本够用了；但是如果（在现在，或者未来，实际的工作环境中）要编写复杂的scala程序，那么还是需要参考Scaladoc的。（纯粹用scala开发spark应用程序，应该不会特别复杂；用scala构建类似于spark的公司内的分布式的大型系统）&lt;/p&gt;
&lt;p&gt;以下是一些Scaladoc使用的tips：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;直接在左上角的搜索框中，搜索你需要的寻找的包、类即可&lt;/li&gt;
&lt;li&gt;C和O，分别代表了类和伴生对象的概念&lt;/li&gt;
&lt;li&gt;t和O，代表了特制(trait)(类似于Java的接口)&lt;/li&gt;
&lt;li&gt;标记为implicit的方法，代表的是隐式转换&lt;/li&gt;
&lt;li&gt;举例：搜索StringOps，可以看到String的增强类，StringOps的所有方法说明&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;2-data-type&#34;&gt;2. Data Type&lt;/h2&gt;
&lt;h3 id=&#34;21-data-type&#34;&gt;2.1 Data Type&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;数据类型&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Byte&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;8位有符号补码整数。数值区间为 -128 到 127&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Short&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;16位有符号补码整数。数值区间为 -32768 到 32767&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Int&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;32位有符号补码整数。数值区间为 -2147483648 到 2147483647&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Long&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;64位有符号补码整数。数值区间为 -9223372036854775808 到 9223372036854775807&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Float&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;32 位, IEEE 754 标准的单精度浮点数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Double&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;64 位 IEEE 754 标准的双精度浮点数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Char&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;16位无符号Unicode字符, 区间值为 U+0000 到 U+FFFF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;String&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;字符序列&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Boolean&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;true或false&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Unit&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;表示无值，和其他语言中void等同。用作不返回任何结果的方法的结果类型。Unit只有一个实例值，写成()。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Null&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;null 或空引用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Nothing&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Nothing类型在Scala的类层级的最底端；它是任何其他类型的子类型。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Any&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Any是所有其他类的超类&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;AnyRef&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;AnyRef类是Scala里所有引用类(reference class)的基类&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;22-valvar--lazy-value&#34;&gt;2.2 val、var &amp;amp; Lazy Value&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;内容是否可变：val修饰的是不可变的，var修饰是可变的&lt;/li&gt;
&lt;li&gt;val修饰的变量在编译后类似于java中的中的变量被final修饰&lt;/li&gt;
&lt;li&gt;lazy修饰符可以修饰变量，但是这个变量必须是val修饰的&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ps. lazy相当于延迟加载（懒加载），当前变量使用lazy修饰的时候，只要变量不被调用，就不会进行初始化，什么时候调用，什么时候进行初始化&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lazy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scala&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;io&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Source&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fromFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/usr/share/dict/words&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mkString&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//当val被声明为lazy时，它的初始化将被推迟，直到我们首次对他取值
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;懒值对于开销大的初始化语句十分有用。它还可以用来应对其他初始化问题，比如循环依赖。更重要的是，它是开发懒数据结构的基础。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//在words被定义时即被取值
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lazy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//在words被首次使用时取值
&lt;/span&gt;&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;words&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;span class=&#34;ln&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//在每一次words被使用时取值
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;3-control-and-function&#34;&gt;3. Control and Function&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;if表达式也有值&lt;/li&gt;
&lt;li&gt;块也有值：是它最后一个表达式的值&lt;/li&gt;
&lt;li&gt;Scala的for循环就像是“增强版”的Java for循环&lt;/li&gt;
&lt;li&gt;分好在绝大数情况下不是必须的&lt;/li&gt;
&lt;li&gt;void类型是Unit&lt;/li&gt;
&lt;li&gt;避免在函数使用return&lt;/li&gt;
&lt;li&gt;注意别再函数式定义中使用return&lt;/li&gt;
&lt;li&gt;异常的工作方式和Java或C++基本一样，不同的是你在catch语句中使用“模式匹配”&lt;/li&gt;
&lt;li&gt;Scala没有受检异常&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;4-array&#34;&gt;4. Array&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;若长度固定可用Array，若长度可能有变化则使用ArrayBuffer&lt;/li&gt;
&lt;li&gt;提供初始值时不要使用new&lt;/li&gt;
&lt;li&gt;用()来访问元素&lt;/li&gt;
&lt;li&gt;用for(elem &amp;lt;- arr)来遍历元素&lt;/li&gt;
&lt;li&gt;用for(elem &amp;lt;- arr if ...) yield ... 来将原数据转型为新数组&lt;/li&gt;
&lt;li&gt;Scala数组和Java数组可以相互操作，用ArrayBuffer，使用scala.collection.JavaConversions中的转换函数&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;5-map-and-tuple&#34;&gt;5. Map and Tuple&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Scala有十分易用的语法来创建、查询和遍历映射(Map)&lt;/li&gt;
&lt;li&gt;你需要从可变的和不可变的映射中做出选择&lt;/li&gt;
&lt;li&gt;默认情况下，你得到的是一个哈希映射(Hash Map)，不过你也可以指明要树形映射&lt;/li&gt;
&lt;li&gt;你可以很容易地在Scala映射和Java映射之间来回切换&lt;/li&gt;
&lt;li&gt;元组可以用来聚集值&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;6-class&#34;&gt;6. Class&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;类中的字段自动带有getter方法和setter方法&lt;/li&gt;
&lt;li&gt;可以用定制的getter/setter方法替换掉字段的定义，而不必修改使用类的客户端——这就是所谓的“统一访问原则”&lt;/li&gt;
&lt;li&gt;用@BeanProperty注解来生成JavaBeans的get*/set*方法&lt;/li&gt;
&lt;li&gt;每个类都有一个主要的构造器，这个构造器和类定义&amp;quot;交织&amp;quot;在一起。它的参数直接为类的字段。主构造器执行类体中所有的语句&lt;/li&gt;
&lt;li&gt;辅助构造器是可选的。他们叫做this&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;7-object&#34;&gt;7. Object&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;对象作为单例或存放工具方法&lt;/li&gt;
&lt;li&gt;类可以拥有一个同名的伴生对象&lt;/li&gt;
&lt;li&gt;对象可以扩展类或特质&lt;/li&gt;
&lt;li&gt;对象的apply方法通常用来构造伴生类的新实例&lt;/li&gt;
&lt;li&gt;如果不想显示定义main方法，可以用扩展App特质的对象&lt;/li&gt;
&lt;li&gt;可以通过扩展Enumeration对象来实现枚举&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;8-package&#34;&gt;8. Package&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;包也可以像内部类那样嵌套&lt;/li&gt;
&lt;li&gt;包路径不是绝对路径&lt;/li&gt;
&lt;li&gt;包声明链x.y.z并不自动将中间包x和x.y变成可见&lt;/li&gt;
&lt;li&gt;位于文件顶部不带花括号的包声明在整个文件范围内有效&lt;/li&gt;
&lt;li&gt;包对象可以持有函数和变量&lt;/li&gt;
&lt;li&gt;引入语句可以引入包、类和对象&lt;/li&gt;
&lt;li&gt;引入语句可以出现在任何位置&lt;/li&gt;
&lt;li&gt;引入语句可以重命名和隐藏特定成员&lt;/li&gt;
&lt;li&gt;java.lang、scala和predef总是被引入&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;9-extends&#34;&gt;9. Extends&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;extends、final关键字和Java中相同&lt;/li&gt;
&lt;li&gt;重写方法时必须用override&lt;/li&gt;
&lt;li&gt;只有主构造器可以用超类的主构造器&lt;/li&gt;
&lt;li&gt;可以重写字段&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;10-fileregex&#34;&gt;10. File&amp;amp;Regex&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Source.fromFile(...).getLines.toArray将交出文件的所有行&lt;/li&gt;
&lt;li&gt;Source.fromFile(...).mkString将以字符串形式交出文件内容&lt;/li&gt;
&lt;li&gt;将字符串转化为数字，可以用toInt或toDouble方法&lt;/li&gt;
&lt;li&gt;使用Java的PrintWriter来写入文本文件&lt;/li&gt;
&lt;li&gt;&amp;quot;正则&amp;quot;.r是一个Regex对象&lt;/li&gt;
&lt;li&gt;如果你的正则表达式包含反斜杠的话，用&amp;quot;&amp;quot;&amp;quot;...&amp;quot;&amp;quot;&amp;quot;&lt;/li&gt;
&lt;li&gt;如果正则模式包含分组，你可以用如下语法来提取它们的内容for(regex(变量1,...,变量n) &amp;lt;- 字符串)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;11-feature&#34;&gt;11. Feature&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;类可以实现任意数量的特质&lt;/li&gt;
&lt;li&gt;特质可以要求实现它们的类具备特定的字段、方法或超类&lt;/li&gt;
&lt;li&gt;和Java接口不同，Scala特质可以提供方法和字段的实现&lt;/li&gt;
&lt;li&gt;当将多个特质叠加在一起时，顺序很重要——其方法先被执行啊的特质排在更后面&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;12-advanced-function&#34;&gt;12. Advanced function&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;函数可以直接赋值给变量，就和数字一样&lt;/li&gt;
&lt;li&gt;可以创建匿名函数，通常还会把它们交给其他函数&lt;/li&gt;
&lt;li&gt;函数参数可以给出需要稍后执行的行为&lt;/li&gt;
&lt;li&gt;许多集合方法都接受函数参数，将函数应用到集合中的值&lt;/li&gt;
&lt;li&gt;有很多语法上的简写让你以简短且易读的方式表达函数参数&lt;/li&gt;
&lt;li&gt;可以创建操作代码块的函数，它们看上去就像是内建的控制语句&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;13-collection&#34;&gt;13. Collection&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;所有集合都扩展自Iterable特质&lt;/li&gt;
&lt;li&gt;集合有三大类，分别为序列、集合映射&lt;/li&gt;
&lt;li&gt;对于几乎所有集合类，Scala都同时提供了可变的和不可变的版本&lt;/li&gt;
&lt;li&gt;Scala列表要么是空的，要么拥有一头一尾，其中尾部本身又是一个列表&lt;/li&gt;
&lt;li&gt;集是无先后次序的集合&lt;/li&gt;
&lt;li&gt;用LinkedHashSet保留插入顺序，或者用SortedSet按顺序进行迭代&lt;/li&gt;
&lt;li&gt;+将元素添加到无先后次序的集合中；+:和:+向前或向后追加到序列；++将两个集合串接在一起；-和--移除元素&lt;/li&gt;
&lt;li&gt;映射、折叠和拉链操作是很有用的技巧，用来将函数或操作应用到集合中的元素&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;14-pattern-match&#34;&gt;14. Pattern match&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;match表达式是一个更好的switch，不会有意外掉入下一个分支的问题&lt;/li&gt;
&lt;li&gt;如果没有模式能够匹配，会抛出MatchError。可以用case _模式来避免&lt;/li&gt;
&lt;li&gt;模式可以包含一个随意定义的条件，称作守卫（guard）&lt;/li&gt;
&lt;li&gt;可以对表达式的类型进行匹配；优先选择模式匹配而不是isInstanceOf/asInstanceOf&lt;/li&gt;
&lt;li&gt;可以匹配数组、元组和样例类的模式，然后将匹配到的不同部分绑定到变量&lt;/li&gt;
&lt;li&gt;在for表达式中，不能匹配的情况会被安静地跳过&lt;/li&gt;
&lt;li&gt;样例类是是编译器会为之自动产出模式匹配所需要的方法的类&lt;/li&gt;
&lt;li&gt;样例类继承层级中的公共超类应该是sealed的&lt;/li&gt;
&lt;li&gt;用Option来存放对于可能存在也可能不存在的值——比null更安全&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;15-annotation&#34;&gt;15. Annotation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;可以为类、方法、字段、局部变量、参数、表达式、类型参数以及各种类型定义添加注解&lt;/li&gt;
&lt;li&gt;对于表达式和类型，注解跟在被注解的条目之后&lt;/li&gt;
&lt;li&gt;注解的形式有 @Annotation、@Annotation(value)或@Annotation(name = value1, ...)&lt;/li&gt;
&lt;li&gt;@volatile、@transient、@strictfp和@native分别生成等效的Java修饰符&lt;/li&gt;
&lt;li&gt;用@throws来生成与Java兼容的throws规格说明&lt;/li&gt;
&lt;li&gt;@tailrec注解让你校验某个递归函数使用了尾递归优化&lt;/li&gt;
&lt;li&gt;assert函数利用了@elidable注解。你可以选择从Scala程序中移除所有断言&lt;/li&gt;
&lt;li&gt;用@deprecated注解来标记已过时的特性&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;16-xml&#34;&gt;16. XML&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;XML字面量&lt;like&gt;this&lt;/like&gt;的类型为NodeSeq&lt;/li&gt;
&lt;li&gt;可以在XML里字面量中嵌套Scala代码&lt;/li&gt;
&lt;li&gt;Node的child属性交出的是子节点&lt;/li&gt;
&lt;li&gt;Node的attributes属性交出的是包含节点属性的MetaData对象&lt;/li&gt;
&lt;li&gt;\和\操作符执行类XPath匹配&lt;/li&gt;
&lt;/ol&gt;
        
      </description>
    </item>
    
  </channel>
</rss>
