<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Data Warehouse: Offline Tuning - JerrysBlog</title><meta name=Description content><meta property="og:title" content="Data Warehouse: Offline Tuning"><meta property="og:description" content="Data warehouse is a system that pulls together data derived from operational systems and external data sources within an organization for reporting and analysis. A data warehouse is a central repository of information that provides users with current and historical decision support information."><meta property="og:type" content="article"><meta property="og:url" content="https://jerrysmd.github.io/20210108_dw-behavior-collection/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-01-08T09:43:01+08:00"><meta property="article:modified_time" content="2021-01-08T09:43:01+08:00"><meta property="og:site_name" content="JerrysBlog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Data Warehouse: Offline Tuning"><meta name=twitter:description content="Data warehouse is a system that pulls together data derived from operational systems and external data sources within an organization for reporting and analysis. A data warehouse is a central repository of information that provides users with current and historical decision support information."><meta name=application-name content="JerrysBlog"><meta name=apple-mobile-web-app-title content="JerrysBlog"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=https://cdn-icons-png.flaticon.com/128/5584/5584593.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=https://jerrysmd.github.io/20210108_dw-behavior-collection/><link rel=prev href=https://jerrysmd.github.io/20201215_parquet-format/><link rel=next href=https://jerrysmd.github.io/20210308_dw-flink/><link rel=stylesheet href=/css/main.css><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/color.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Data Warehouse: Offline Tuning","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jerrysmd.github.io\/20210108_dw-behavior-collection\/"},"genre":"posts","keywords":"DataWarehouse, Tuning","wordcount":1095,"url":"https:\/\/jerrysmd.github.io\/20210108_dw-behavior-collection\/","datePublished":"2021-01-08T09:43:01+08:00","dateModified":"2021-01-08T09:43:01+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Author"},"description":""}</script><script src=//instant.page/5.1.1 defer type=module integrity=sha384-MWfCL6g1OTGsbSwfuMHc8+8J2u71/LA8dzlIN3ycajckxuZZmF+DNjdm7O6H3PSq></script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark"),window.theme=e,window.isDark=window.theme!=="light"}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"||"auto"==="black"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")],window.switchThemeEventSet=new Set</script><div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=JerrysBlog><span class=header-title-pre><i class='far fa-edit fa-fw' aria-hidden=true></i></span>JERRYSBLOG</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/ title=Home>Home </a><a class=menu-item href=/categories/technology/ title="Technology article list">Technology </a><a class=menu-item href=/categories/life/ title="Life article list">Life </a><a class=menu-item href=/tags/ title="Tags cloud">Tags </a><a class=menu-item href=/about/ title="About blog">About </a><a class=menu-item href=https://github.com/Jerrysmd title=GitHub rel="noopener noreferrer" target=_blank><i class='fab fa-github fa-fw' aria-hidden=true></i> </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw"></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw"></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=JerrysBlog><span class=header-title-pre><i class='far fa-edit fa-fw' aria-hidden=true></i></span>JERRYSBLOG</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw"></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw"></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/ title=Home>Home</a><a class=menu-item href=/categories/technology/ title="Technology article list">Technology</a><a class=menu-item href=/categories/life/ title="Life article list">Life</a><a class=menu-item href=/tags/ title="Tags cloud">Tags</a><a class=menu-item href=/about/ title="About blog">About</a><a class=menu-item href=https://github.com/Jerrysmd title=GitHub rel="noopener noreferrer" target=_blank><i class='fab fa-github fa-fw' aria-hidden=true></i></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto><nav id=TableOfContents><ul><li><a href=#数据仓库>数据仓库</a><ul><li><a href=#概念>概念</a></li><li><a href=#技术组件>技术组件</a></li><li><a href=#系统流程>系统流程</a></li><li><a href=#集群配置>集群配置</a></li></ul></li><li><a href=#数据采集模块>数据采集模块</a><ul><li><a href=#hadoop>Hadoop</a></li><li><a href=#zookeeper>Zookeeper</a></li><li><a href=#kafka>Kafka</a></li><li><a href=#flume>Flume</a></li><li><a href=#datax>DataX</a></li><li><a href=#maxwell>Maxwell</a></li></ul></li><li><a href=#数据采集模块总结>数据采集模块总结</a><ul><li><a href=#linux>Linux</a></li><li><a href=#sqoop>Sqoop</a></li><li><a href=#hadoop-1>Hadoop</a></li><li><a href=#hdfs>HDFS</a></li><li><a href=#mapreduce>Mapreduce</a></li><li><a href=#yarn>Yarn</a></li><li><a href=#zookeeper-1>Zookeeper</a></li><li><a href=#flume-1>Flume</a></li><li><a href=#kafka-1>Kafka</a></li><li><a href=#hive>Hive</a></li></ul></li><li><a href=#数据仓库-1>数据仓库</a><ul><li><a href=#数据分层>数据分层</a></li><li><a href=#数仓建模>数仓建模</a></li><li><a href=#数据处理>数据处理</a></li></ul></li></ul></nav></div></div><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Data Warehouse: Offline Tuning</h1><div class=post-meta><div class=post-meta-line><span class=post-author><span class="author fas fa-user-circle fa-fw"></span><a href=/ title=Author rel=author class=author>Author</a>
</span>&nbsp;<span class=post-category>included in </span>&nbsp;<span class=post-category>category <a href=/categories/technology/><i class="far fa-folder fa-fw"></i>Technology</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2021-01-08>2021-01-08</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2021-01-08>2021-01-08</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1095 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;6 minutes&nbsp;<span id=/20210108_dw-behavior-collection/ class=leancloud_visitors data-flag-title="Data Warehouse: Offline Tuning">
<i class="far fa-eye fa-fw"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;views
</span>&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#数据仓库>数据仓库</a><ul><li><a href=#概念>概念</a></li><li><a href=#技术组件>技术组件</a></li><li><a href=#系统流程>系统流程</a></li><li><a href=#集群配置>集群配置</a></li></ul></li><li><a href=#数据采集模块>数据采集模块</a><ul><li><a href=#hadoop>Hadoop</a></li><li><a href=#zookeeper>Zookeeper</a></li><li><a href=#kafka>Kafka</a></li><li><a href=#flume>Flume</a></li><li><a href=#datax>DataX</a></li><li><a href=#maxwell>Maxwell</a></li></ul></li><li><a href=#数据采集模块总结>数据采集模块总结</a><ul><li><a href=#linux>Linux</a></li><li><a href=#sqoop>Sqoop</a></li><li><a href=#hadoop-1>Hadoop</a></li><li><a href=#hdfs>HDFS</a></li><li><a href=#mapreduce>Mapreduce</a></li><li><a href=#yarn>Yarn</a></li><li><a href=#zookeeper-1>Zookeeper</a></li><li><a href=#flume-1>Flume</a></li><li><a href=#kafka-1>Kafka</a></li><li><a href=#hive>Hive</a></li></ul></li><li><a href=#数据仓库-1>数据仓库</a><ul><li><a href=#数据分层>数据分层</a></li><li><a href=#数仓建模>数仓建模</a></li><li><a href=#数据处理>数据处理</a></li></ul></li></ul></nav></div></div><div class=content id=content><p>Data warehouse is a system that pulls together data derived from operational systems and external data sources within an organization for reporting and analysis. A data warehouse is a central repository of information that provides users with current and historical decision support information.</p><h2 id=数据仓库 class=headerLink><a href=#%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93 class=header-mark></a>数据仓库</h2><h3 id=概念 class=headerLink><a href=#%e6%a6%82%e5%bf%b5 class=header-mark></a>概念</h3><p><figure><a class=lightgallery href=/20210108_dw-behavior-collection/dataWarehouse_introduction.jpg title=dataWarehouse_introduction data-thumbnail=/20210108_dw-behavior-collection/dataWarehouse_introduction.jpg data-sub-html="<h2>offline DW process</h2><p>dataWarehouse_introduction</p>"><img loading=lazy src=/20210108_dw-behavior-collection/dataWarehouse_introduction.jpg srcset="/20210108_dw-behavior-collection/dataWarehouse_introduction.jpg, /20210108_dw-behavior-collection/dataWarehouse_introduction.jpg 1.5x, /20210108_dw-behavior-collection/dataWarehouse_introduction.jpg 2x" sizes=auto alt=/20210108_dw-behavior-collection/dataWarehouse_introduction.jpg></a><figcaption class=image-caption>offline DW process</figcaption></figure></p><blockquote><p>数仓是对数据进行 <strong>备份、清洗、聚合、统计</strong> 等操作。</p><p>ODS原始数据层；DWD明细数据层；DWS服务数据层；DWT数据主题层；ADS数据应用层</p></blockquote><h3 id=技术组件 class=headerLink><a href=#%e6%8a%80%e6%9c%af%e7%bb%84%e4%bb%b6 class=header-mark></a>技术组件</h3><ul><li>数据采集传输：<code>Flume，Kafka，DataX</code>，Sqoop，Logstash</li><li>数据存储：<code>MySQL，HDFS，HBASE</code>，Redis，MongoDB</li><li>数据计算：<code>Hive，Spark</code>，Flink，Tez，Storm</li><li>数据查询：<code>Presto，Kylin</code>，Impala，Druid</li><li>数据可视化：Echarts、<code>Superset</code>、QuickBI、DataV</li><li>任务调度：Azkaban、Oozie</li><li>集群监控：Zabbix</li><li>元数据管理：Atlas</li><li>权限管理：Ranger</li></ul><h3 id=系统流程 class=headerLink><a href=#%e7%b3%bb%e7%bb%9f%e6%b5%81%e7%a8%8b class=header-mark></a>系统流程</h3><ul><li><p><code>业务数据 / 前端 js 数据：</code>持久化或不持久化写入数据库。</p></li><li><p><code>Nginx：</code>负载均衡，使每个节点数据量保持合理。</p></li><li><p><code>Flume：</code>采集日志。可以直接采集到 Hadoop，但 hadoop 可能处理很慢，如双11。可以先写到 Kafka 里。</p><p>Flume 组成，Put 事务，Take 事务</p><p>Flume 三个器：拦截器，选择器，监控器</p><p>Flume 优化：内存，台数</p></li><li><p><code>Kafka：</code>23 件事</p><p>1.kafka基本信息 2.挂了 3.丢失 4.重复 5.积压 6.优化 7.高效读写的原因</p></li><li><p><code>Zookeeper：</code>分布式协调</p><p>1.部署多少台 2.选举机制，Paxos算法</p></li><li><p><code>Flume：</code> 消费传到 Hadoop</p></li><li><p><code>Hive：</code> 1.Hive内部表、外部表区别 2.4个by 3.系统函数 4.UDF、UDTF函数 5.窗口函数 6.Hive优化 7.数据倾斜 8.Hive引擎 9.元数据备份</p></li></ul><h3 id=集群配置 class=headerLink><a href=#%e9%9b%86%e7%be%a4%e9%85%8d%e7%bd%ae class=header-mark></a>集群配置</h3><p>配置原则:</p><ol><li>消耗内存的组件要分开：HDFS 的 NameNode、Yarn 的 ResourceManager 分开配置</li><li>kafka、zk、flume 传输数据比较紧密的放在一起</li><li>客户端放在一到两台服务器上，方便外部访问</li></ol><h2 id=数据采集模块 class=headerLink><a href=#%e6%95%b0%e6%8d%ae%e9%87%87%e9%9b%86%e6%a8%a1%e5%9d%97 class=header-mark></a>数据采集模块</h2><h3 id=hadoop class=headerLink><a href=#hadoop class=header-mark></a>Hadoop</h3><blockquote><p>优化：</p><ol><li><p>数据均衡：节点与节点间，磁盘与磁盘间，都可以使用命令使数据均衡，threshold 设置差值。</p></li><li><p>LZO 压缩：hadoop 额外支持 gzip、Snappy、Lzo、Lzop(分片) 压缩方式。LZO创建索引后可以实现分片。</p></li></ol><p>需要压缩的三个地方：</p><table><thead><tr><th></th><th>Map</th><th></th><th>Reduce</th><th></th></tr></thead><tbody><tr><td>输入端</td><td></td><td>快</td><td></td><td>输出端</td></tr><tr><td>先考虑数据量<br>1.小 => 快</td><td></td><td>snappy</td><td></td><td>看需求<br>1.永久保存：压缩越小越好</td></tr><tr><td>2.数据量大 => 切片<br>bzip2<br>lzo => 需要创建索引</td><td></td><td>lzo</td><td></td><td>2.下一个mapreduce输入端<br>数据量小 => 快<br>数据量大 => 切片 压缩</td></tr></tbody></table><ol start=3><li>HDFS参数调优：</li><li>对于大集群或者大量客户端的集群来说，通常需要调大 dfs.namenode.handler.count 的个数，默认值为10个。建议调整为 20 * loge<sup>cluster size</sup></li><li>Yarn参数调优 yarn-site.xml：</li><li>情景描述：总共7台机器，每天几亿条数据，数据源 -> Flume -> Kafka -> HDFS -> Hive</li><li>问题：数据统计主要用 HiveSQL，没有数据倾斜，小文件已经做了合并处理，开启了 JVM 重用，而且IO 没有阻塞，<strong>内存用了不到 50%</strong>，但还是跑的非常慢，而且数据量洪峰时，整个集群都会宕掉，基于这种情况的优化方案是什么。</li><li>解决办法：典型的内存利用率不够，一般是 Yarn 的2个配置造成的，<strong>单个任务可以申请的最大内存大小</strong>，和 <strong>Hadoop 单个节点可用内存大小</strong>。调节这两个参数能提高系统内存的利用率。 （NodeManager 默认内存大小 8g，单个任务默认内存大小 8g，maptask默认内存大小 1g，reducetask默认内存大小 1g。）NodeManager内存改为节点 80% 左右的内存大小。单个任务内存大小根据每 128M 数据分配1g内存。maptask 和 reducetask 内存若不支持压缩也需要调大。</li></ol></blockquote><h3 id=zookeeper class=headerLink><a href=#zookeeper class=header-mark></a>Zookeeper</h3><h3 id=kafka class=headerLink><a href=#kafka class=header-mark></a>Kafka</h3><blockquote><p>kafka 机器数量计算：</p><p>机器数量（经验公式）= 2 *（峰值生产速度 * 副本数 / 100) + 1</p><p>先通过压测拿到峰值生产速度，比如峰值生产速度是 50M/s。副本数默认是1个，生产环境可以设置为2。Kafka 机器数量 = 2 * （50 * 2 / 100）+ 1 = 3 台。</p></blockquote><blockquote><p>kafka producer 生产者压力测试：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>bin/kafka-producer-perf-test.sh --topic <span class=nb>test</span> --record-size <span class=m>100</span> --num-records <span class=m>100000</span> --throughput -1 --producer-props bootstrap.servers<span class=o>=</span>hadoop102:9092,hadoop103:9092
</span></span></code></pre></td></tr></table></div></div><p>参数说明：</p><p>&ndash;record-size：是一条信息有多大，单位是字节。</p><p>&ndash;num-records：是总共发送多少条信息。</p><p>&ndash;throughput：是每秒多少条信息，设成-1表示不限流，可测出生产者最大吞吐量。</p></blockquote><blockquote><p>kafka consumer 消费者压力测试：</p><p>如果 IO、CPU、内存、网络 这四个指标都不能改变，考虑增加分区数来提升性能。</p><p>参数说明：</p><p>&ndash;broker-list：指定 kafka 集群地址</p><p>&ndash;topic：指定 topic 的名称</p><p>&ndash;fetch-size：指定每次 fetch 的数据大小</p><p>&ndash;messages：总共要消费的消息个数</p></blockquote><blockquote><p>kafka 分区数计算：</p><ol><li>创建一个只有一个分区的topic</li><li>测试这个 topic 的 producer 吞吐量和 consumer 吞吐量。</li><li>假设他们的值是 Tp 和 Tc，单位是 MB/s。</li><li>然后假设总的目标吞吐量是 Tt，那么分区数 = Tt/min( Tp，Tc)</li><li>分区数一般设置为：3 - 10个</li></ol></blockquote><h3 id=flume class=headerLink><a href=#flume class=header-mark></a>Flume</h3><blockquote><p>Flume 组件选型</p><ol><li><p>Source：</p><ol><li>Taildir Source：支持断点续传、多目录。但可能有数据重复（重复数据在下一级解决：在 hive 的 dwd 层、spark streaming 使用 group by、开窗取窗口第一条数据）</li></ol></li><li><p>Channel：</p><ol><li><p>kafka channel：数据存放在 kafka 里面。kafka 数据存在磁盘里。</p><p><strong>基于磁盘，可靠性高</strong></p><p>kafka channel > memory channel + kafka sink</p><p>如果下一级是 kafka，优先选择 kafka channel</p><p>如果下一级不是 kafka，对可靠性要求比较高，金融领域，优先选择 file channel</p><p>如果下一级不是 kafka，对可靠性要求不高，选择 memory channel，追求效率</p><p>kafka channel 1.6版本产生，但有 bug 产生的数据是 header + 内容，1.7 版本解决</p></li></ol></li></ol></blockquote><blockquote><p>Flume 拦截器</p><p>Flume 消费 Kafka 里面的数据时，可能已经是第二天，数据有可能发往第二天的 HDFS 路径。</p><p>解决思路：拦截 json 日志，通过 fastjson 解析 json，获取实际时间 ts。将获取的 ts 时间写入拦截器 header 头，header 的 key 必须是 <strong>timestamp，因为 Flume 框架会根据这个 key 的值识别为时间，写入到 HDFS。</strong></p><ol><li>创建 Maven 工程 flume-interceptor</li><li>创建包名：com.whatever.flume.interceptor</li><li>在 pom.xml 文件中添加配置</li><li>在 com.whatever.flume.interceptor 包下创建 JSONUtils 类</li><li>在 com.whatever.flume.interceptor 包下创建 ETLInterceptor 类，重写方法，判断是否符合 JSON 格式</li><li>打包，分发到 Flume 节点</li></ol></blockquote><blockquote><p><figure><a class=lightgallery href=/20210108_dw-behavior-collection/flume_scs.jpg title=flume_scs data-thumbnail=/20210108_dw-behavior-collection/flume_scs.jpg data-sub-html="<h2>flume_scs</h2><p>flume_scs</p>"><img loading=lazy src=/20210108_dw-behavior-collection/flume_scs.jpg srcset="/20210108_dw-behavior-collection/flume_scs.jpg, /20210108_dw-behavior-collection/flume_scs.jpg 1.5x, /20210108_dw-behavior-collection/flume_scs.jpg 2x" sizes=auto alt=/20210108_dw-behavior-collection/flume_scs.jpg></a><figcaption class=image-caption>flume_scs</figcaption></figure></p></blockquote><blockquote><p>Flume优化：</p><ol><li>内存参数设置优化：<ol><li>JVM heap 一般设置为 4G 或更高</li><li>-Xmx（启动内存） 与 -Xms（运行内存） 最好设置一致，减少内存抖动带来的性能影响，如果不一致容易倒置 fullgc</li></ol></li></ol></blockquote><h3 id=datax class=headerLink><a href=#datax class=header-mark></a>DataX</h3><blockquote><p>同步策略：</p><table><thead><tr><th>同步策略</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>全量同步</td><td>逻辑简单</td><td>效率低</td></tr><tr><td>增量同步</td><td>效率高，无需同步和存储重复数据</td><td>逻辑复杂</td></tr></tbody></table></blockquote><blockquote><p>DadaX 相比 Sqoop 功能更强大：</p><table><thead><tr><th>功能</th><th>DataX</th><th>Sqoop</th></tr></thead><tbody><tr><td>运行模式</td><td>单进程多线程</td><td>MR</td></tr><tr><td>分布式</td><td>不支持<br>可以通过调度系统规避</td><td>支持</td></tr><tr><td>流控</td><td>有</td><td>需定制</td></tr><tr><td>统计信息</td><td>有</td><td>分布式数据收集不方便</td></tr><tr><td>数据校验</td><td>有</td><td>需定制</td></tr><tr><td>监控</td><td>需定制</td><td>需定制</td></tr></tbody></table></blockquote><blockquote><p>DataX 调度决策思路：</p><p>举例，用户提交了一个 DataX 作业，并且配置了总的并发数为 20，目的是对一个有 100 张分表的 MySQL 进行同步。调度决策思路是：</p><ol><li>dataX job 根据分库分表切分策略，将同步工作分成 100 个 Task。</li><li>根据配置的总的并发度 20，以及每个 TaskGroup 的并发度 5，dataX共需要 4 个 TaskGroup。</li><li>4 个 TaskGroup 分 100 个 Task，每个 TaskGroup 负责 25个 Task。</li></ol></blockquote><blockquote><p>同步 HDFS 数据到 MySQL 案例：</p><p>选用 HDFSReader 和 MySQLWriter，分别设置 json 配置文件。</p></blockquote><blockquote><p>DataX优化：</p><p>提升 DataX job 内 channel 并发数，内存的占用显著增加，每个 channel 会有一个 Buffer，作为临时数据交换的缓冲区，而在 reader 和 writer 中，也会有 buffer，为了防止 OOM，需要调大 JVM 的堆内存。</p><p>调整 JVM xms xmx 参数的两种方式：一种是直接更改 datax.py 脚本；另一种是在启动的时候，加上参数：</p><p><code>python datax/bin/datax.py --jvm="-Xms8G -Xmx8G" /path/to/your/job.json</code></p></blockquote><h3 id=maxwell class=headerLink><a href=#maxwell class=header-mark></a>Maxwell</h3><blockquote><p>MySQL 变更数据抓取软件，实时监控 MySQL 的 insert、update、delete。并将变更数据发送给 Kafka 等流数据处理平台。</p></blockquote><blockquote><p>原理：</p><p>读取 MySQL 的二进制日志（Binlog），从中获取变更数据。</p></blockquote><h2 id=数据采集模块总结 class=headerLink><a href=#%e6%95%b0%e6%8d%ae%e9%87%87%e9%9b%86%e6%a8%a1%e5%9d%97%e6%80%bb%e7%bb%93 class=header-mark></a>数据采集模块总结</h2><h3 id=linux class=headerLink><a href=#linux class=header-mark></a>Linux</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 命令</span>
</span></span><span class=line><span class=cl>top
</span></span><span class=line><span class=cl>ps -ef
</span></span><span class=line><span class=cl>df -h	<span class=c1>#磁盘空间</span>
</span></span><span class=line><span class=cl>netstat	<span class=c1>#查看端口号</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4个工具</span>
</span></span><span class=line><span class=cl>awk sed sort cut
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 写过什么脚本</span>
</span></span><span class=line><span class=cl>1. 同步分发
</span></span><span class=line><span class=cl>2. 启动停止
</span></span></code></pre></td></tr></table></div></div><h3 id=sqoop class=headerLink><a href=#sqoop class=header-mark></a>Sqoop</h3><blockquote><p>导入数据的方式：</p><ul><li>全量：where 1=1</li><li>增量：where 创建时间 = 当天</li><li>新增及变化：where 创建时间 = 当天 or 操作时间 = 当天</li><li>特殊：只导入一次</li></ul></blockquote><h3 id=hadoop-1 class=headerLink><a href=#hadoop-1 class=header-mark></a>Hadoop</h3><blockquote><p>常用端口号：</p><ul><li>2.x：50070/8020：HDFS 8088：任务情况 19888：Job history</li><li>3.x：9870/8020：HDFS 8088：任务情况 19888：Job history</li></ul></blockquote><blockquote><p>配置文件：</p><ul><li>/etc/profile</li><li>2.x：core-site.xml hdfs-site.xml yarn-site.xml mapred-site.xml slaves</li><li>3.x：core-site.xml hdfs-site.xml yarn-site.xml mapred-site.xml workers</li></ul></blockquote><h3 id=hdfs class=headerLink><a href=#hdfs class=header-mark></a>HDFS</h3><blockquote><p>HDFS 的读写流程，笔试：</p><p>写详细步骤：</p><ol><li>客户端向NameNode发出写文件请求。</li><li>检查是否已存在文件、检查权限。若通过检查，直接先将操作写入EditLog，并返回输出流对象。
（注：WAL，write ahead log，先写Log，再写内存，因为EditLog记录的是最新的HDFS客户端执行所有的写操作。如果后续真实写操作失败了，由于在真实写操作之前，操作就被写入EditLog中了，故EditLog中仍会有记录，我们不用担心后续client读不到相应的数据块，因为在第5步中DataNode收到块后会有一返回确认信息，若没写成功，发送端没收到确认信息，会一直重试，直到成功）</li><li>client端按128MB的块切分文件。</li><li>client将NameNode返回的分配的可写的DataNode列表和Data数据一同发送给最近的第一个DataNode节点，此后client端和NameNode分配的多个DataNode构成pipeline管道，client端向输出流对象中写数据。client每向第一个DataNode写入一个packet，这个packet便会直接在pipeline里传给第二个、第三个…DataNode。
（注：并不是写好一个块或一整个文件后才向后分发）</li><li>每个DataNode写完一个块后，会返回确认信息。
（注：并不是每写完一个packet后就返回确认信息，因为packet中的每个chunk都携带校验信息，没必要每写一个就汇报一下，这样效率太慢。正确的做法是写完一个block块后，对校验信息进行汇总分析，就能得出是否有块写错的情况发生）</li><li>写完数据，关闭输输出流。</li><li>发送完成信号给NameNode。
（注：发送完成信号的时机取决于集群是强一致性还是最终一致性，强一致性则需要所有DataNode写完后才向NameNode汇报。最终一致性则其中任意一个DataNode写完后就能单独向NameNode汇报，HDFS一般情况下都是强调强一致性）</li></ol><p>读详细步骤：</p><ol><li>client访问NameNode，查询元数据信息，获得这个文件的数据块位置列表，返回输入流对象。</li><li>就近挑选一台datanode服务器，请求建立输入流 。</li><li>DataNode向输入流中中写数据，以packet为单位来校验。</li><li>关闭输入流</li></ol></blockquote><blockquote><p>小文件危害：</p><ol><li>存储时间：小文件会占用 namenode 一整个区块，一个文件块150字节。128g内存的 namenode 能存储 9亿个文件块。</li><li>计算时间：1个文件块开启1个maptask，一个maptask就是1g内存。</li></ol><p>如何解决：</p><ol><li>合并：CombineTextinputformat => 减少 maptask</li><li>har归档</li><li>JVM重用</li></ol></blockquote><blockquote><p>HDFS 有几个副本：</p><p>3</p></blockquote><blockquote><p>HDFS 块大小：</p><p>2.x 3.x：128M</p></blockquote><h3 id=mapreduce class=headerLink><a href=#mapreduce class=header-mark></a>Mapreduce</h3><blockquote><p>shuffle 及其优化：</p><p>shuffle 定义：map 方法之后，reduce方法之前混洗的过程。</p><p>map 阶段之后：</p><ol><li>先调用 getpartition 方法，标记数据是哪一个分区。</li><li>进入环形缓冲区（缓冲区大小100M ），到达 80% 进行溢写（排序手段：对 <strong>key</strong> 的索引按照 <strong>字典序</strong> 进行 <strong>快排</strong>）</li><li>对溢写文件进行归并，写到指定磁盘，持久化到磁盘。</li></ol><p>reduce 阶段之前：</p><ol><li>拉取磁盘上指定的数据，放到内存中（内存不够在磁盘中）</li><li>reduce 操作</li></ol><p>优化：</p><ol><li><p>getpartition 方法时：自定义分区：解决数据倾斜问题。</p></li><li><p>调整缓冲区大小和溢写阈值，缓冲区大小由100M调整到200M，溢写阈值由80%调整到90%。产生大量的溢写文件，使用combiner聚类文件（前提是不影响最终业务逻辑）。这样减少了写文件的个数，合并会快一些。</p></li><li><p>溢写文件归并到磁盘：减少磁盘IO压缩，使用快的压缩算法：snappy/lzo</p></li><li></li><li><table><thead><tr><th></th><th>Map</th><th></th><th>Reduce</th><th></th></tr></thead><tbody><tr><td>输入端</td><td></td><td>快</td><td></td><td>输出端</td></tr><tr><td>先考虑数据量<br>1.小 => 快</td><td></td><td>snappy</td><td></td><td>看需求<br>1.永久保存：压缩越小越好</td></tr><tr><td>2.数据量大 => 切片<br>bzip2<br>lzo => 需要创建索引</td><td></td><td>lzo</td><td></td><td>2.下一个mapreduce输入端<br>数据量小 => 快<br>数据量大 => 切片 压缩</td></tr></tbody></table></li><li><p>reduce 拉取磁盘指定的数据，默认拉取5个，可以改成10 - 20个</p></li><li><p>yarn 和 hadoop内存大小调整：<strong>单个任务可以申请的最大内存大小</strong>，和 <strong>Hadoop 单个节点可用内存大小</strong>。调节这两个参数能提高系统内存的利用率。 （NodeManager 默认内存大小 8g，单个任务默认内存大小 8g，maptask默认内存大小 1g，reducetask默认内存大小 1g。）NodeManager内存改为节点 80% 左右的内存大小。单个任务内存大小根据每 128M 数据分配1g内存。maptask 和 reducetask 内存若不支持压缩也需要调大。</p></li></ol></blockquote><blockquote><p>进行了几次排序：</p><p>map后进行一次快排，一次归并。</p><p>reduce时进行一次归并，一次分组。</p></blockquote><h3 id=yarn class=headerLink><a href=#yarn class=header-mark></a>Yarn</h3><blockquote><p>yarn 的工作机制：</p><ol><li><p>用户使用客户端向 RM 提交一个任务，同时指定提交到哪个队列和需要多少资源。用户可以通过每个计算引擎的对应参数设置，如果没有特别指定，则使用默认设置。</p></li><li><p>RM 在收到任务提交的请求后，先根据资源和队列是否满足要求选择一个 NM，通知它启动一个特殊的 container，称为 ApplicationMaster（AM），后续流程由它发起。</p></li><li><p>AM 向 RM 注册后根据自己任务的需要，向 RM 申请 container，包括数量、所需资源量、所在位置等因素。</p></li><li><p>如果队列有足够资源，RM 会将 container 分配给有足够剩余资源的 NM，由 AM 通知 NM 启动 container。</p></li><li><p>container 启动后执行具体的任务，处理分给自己的数据。NM 除了负责启动 container，还负责监控它的资源使用状况以及是否失败退出等工作，如果 container 实际使用的内存超过申请时指定的内存，会将其杀死，保证其他 container 能正常运行。</p></li><li><p>各个 container 向 AM 汇报自己的进度，都完成后，AM 向 RM 注销任务并退出，RM 通知 NM 杀死对应的 container，任务结束。</p></li></ol></blockquote><blockquote><p>hadoop 调度器：</p><ol><li>三种调度器：FIFO、容量调度器、公平调度器</li><li>Apache默认调度器：容量调度器（apache默认资源很小）</li><li>CDH默认调度器：公平调度器</li><li>特点：<ol><li>FIFO调度器特点：支持单队列，任务先进先出，企业中几乎不用。</li><li>容量调度器：底层是FIFO调度器。支持多队列，可以借用其他队列资源。先进入的任务优先执行。</li><li>公平调度器：支持多队列(并发度比容量调度高)，可以借用其他队列资源。队列中所有任务公平享有队列资源。</li></ol></li><li>容器调度器配置多队列：<ol><li>按照分析引擎创建队列：mr、spark、flink、hive</li><li>按照业务：登录、注册、购物车、下单、支付</li></ol></li></ol></blockquote><h3 id=zookeeper-1 class=headerLink><a href=#zookeeper-1 class=header-mark></a>Zookeeper</h3><blockquote><p>选举机制：</p><ol><li>半数机制：3台服务器，2台投谁谁就是老大</li></ol></blockquote><blockquote><p>常用命令：</p><p><code>delete create</code></p></blockquote><blockquote><p>安装台数：</p><p>根据集群机器数量，3-11台。zk台数多了，增加可靠性，但降低选举效率。</p></blockquote><h3 id=flume-1 class=headerLink><a href=#flume-1 class=header-mark></a>Flume</h3><blockquote><p>组成：（source、channel、sink、put事务、take事务）</p><ol><li>source：（Taildirsource）<ol><li>优点：断点续传、多目录，实时监控。缺点：文件名更名(如log4j就是更名的日志框架)之后重新读取该文件造成重复。注意：让Taildirsource判断文件时只看iNode值</li><li>Apache 1.7、CDH1.6版本产生的</li><li>没有断点续传怎么办：自定义 source，读取的位置始终持久到磁盘上</li><li>挂了：不会丢数据，但有可能重复数据</li><li>如何处理重复数据：不处理或下一级处理，采用事务方式效率太低</li><li>不支持递归遍历文件夹：自定义递归</li></ol></li><li>channel：（KafkaChannel）<ol><li>优点：将数据写入Kafka，省了一层sink</li><li>file channel 磁盘|可靠性高|性能低</li><li>memory channel 内存|可靠性低|性能高</li><li>kafka channel 存kafka里，kafka存在磁盘|可靠性高|性能优于 memory channel + kafka sink</li></ol></li><li>sink：（HDFS sink）<ol><li>用来解决小文件问题</li><li>设置大小128M、时间（1-2小时）、event个数禁止0</li></ol></li></ol></blockquote><blockquote><p>KafkaChannel：在kafka中既可以生产者也可以作为消费者
用法：</p><ol><li>source - kafkachannel - sink</li><li>source - kafkachannel（作为消费者）</li><li>kafkachannel - sink（作为生产者）</li></ol></blockquote><blockquote><p>三个器：（拦截器、选择器、监控器）</p><ol><li>拦截器：时间戳拦截器 或者 自定义拦截器</li><li>选择器：默认是replicating，把数据发往下一级所有通道</li><li>监控器：g, 监控 put、take 事务尝试提交的次数远远大于最终提交成功的次数，说明 flume 异常。自身：增加内存，其他：增加 flume 台数</li></ol></blockquote><blockquote><p>优化：</p><ol><li>file channel 能配置多目录就配置多目录（不同磁盘）</li><li>使用 HDFS sink 用来解决小文件问题</li><li>通过监控器找寻原因，增加内存和台数</li></ol></blockquote><blockquote><p>挂了恢复：</p><ol><li>channel 挂了：memory channel 100个event 数据丢失。（file channel 100万个event，没有丢失风险）</li><li>taildir source 挂了：不会丢数，可能重复数据</li></ol></blockquote><h3 id=kafka-1 class=headerLink><a href=#kafka-1 class=header-mark></a>Kafka</h3><blockquote><p>基本信息：</p><ol><li>组成：<ol><li>producer：<ol><li>ACK：0 1 -1</li><li>拦截器，序列化器，分区器</li><li>发送流程</li><li>幂等性，事务</li><li>分区规则： 有指定分区则发往指定分区 ；没有指定分区，则根据key值Hash；没有指定分区也没有key的时候，轮询（粘性）</li></ol></li><li>broker：<ol><li>Topic：副本（高可靠）<ol><li>ISR：LEO、HW</li></ol></li><li>分区（高并发，负载均衡，防止热点）</li></ol></li><li>consumer<ol><li>分区分配规则</li><li>offset保存：<ol><li>默认：__consumer_offsets主题。</li><li>其他：手动维护Offset（MySQL）</li><li>保存数据&保存Offset写到一个事物</li><li>精准一次消费</li><li>先保存数据后保存Offset 重复数据+幂等性（精准一次消费）</li><li>先保存Offset后保存数据 丢失数据</li></ol></li></ol></li><li>zk：存放 broker（id, topic），consumer（相应的 offset），没有生产者信息</li></ol></li><li>安装台数：<code>2 * (生产者峰值生产速率(压测) * 副本 / 100) + 1</code>,<ol><li>先使用3台机器压测</li></ol></li><li>副本数：通常2个副本，默认1个副本。多：可靠性高，传输性能差</li><li>数据量：100万日活 一人100条 一条1k。 1M/s</li><li>数据保存多久：3天</li><li>磁盘预留：100g(一天数据) * 2个副本 * 3天 / 0.7</li><li>监控：kafka egale：开源框架</li><li>分区：提高并发度：先设置1个，通过压测生产者峰值生产速率tp、消费者峰值消费速率tc<ol><li>期望吞吐量t 100m/s</li><li>分区数 = t / min (tp, tc)</li></ol></li><li>分区分配策略：<ol><li>range 默认</li><li>roundrobin 采用 roundrobin 所有数据采用 hash 方式大散，再采用轮询的方式执行</li></ol></li><li>isr：主要解决leader挂了谁当老大，在 isr 队列的都有机会当老大。</li><li>多少个 topic：满足下一级消费者即可。</li></ol></blockquote><blockquote><p>挂了:</p><ol><li>短期：flume channel 缓冲数据</li><li>长期：日志服务器保留30天日志</li></ol></blockquote><blockquote><p>丢：ack 配置参数</p><ul><li>0：发送数据，不需要应答。可靠性最差，传输性能最好。</li><li>1：发送数据，leader 应答。可靠性一般，传输性能一般。</li><li>-1：发送数据，leader 和 follower 共同应答。可靠性最高，传输性能最差。</li><li>企业中：0几乎不用，不太重要1，重要-1</li></ul></blockquote><blockquote><p>重复：</p><ol><li>采用 事务、幂等性、ack = -1<ol><li>幂等性：单分区单会话内数据不重复</li><li>事务：每条数据比较，可以比较多个分区</li><li>事务：</li></ol></li><li>在下一级处理：</li></ol></blockquote><blockquote><p>积压：kafka 保存数据的时间是有限的，没有及时消费完</p><ol><li>增加分区，同时增加消费者对应的CPU核数</li><li>增加消费者 batchsize</li></ol></blockquote><blockquote><p>优化：</p><ol><li>日志保存3天</li><li>增加网络通信延迟时间</li></ol></blockquote><blockquote><ol><li>高效读写原因：<ol><li>集群，分区</li><li>顺序读写600m/s(vip)，随机读写100m/s</li><li>零拷贝</li></ol></li><li>传输一条2m日志文件，现象：卡住。调整两个参数大小</li><li>数据过期：删除 或者 压缩，通常删除，副本备份30天数据</li></ol></blockquote><h3 id=hive class=headerLink><a href=#hive class=header-mark></a>Hive</h3><blockquote><p>组成：<figure><a class=lightgallery href=/20210108_dw-behavior-collection/hive_structure.jpg title=hive_structure data-thumbnail=/20210108_dw-behavior-collection/hive_structure.jpg data-sub-html="<h2>hive_structure</h2><p>hive_structure</p>"><img loading=lazy src=/20210108_dw-behavior-collection/hive_structure.jpg srcset="/20210108_dw-behavior-collection/hive_structure.jpg, /20210108_dw-behavior-collection/hive_structure.jpg 1.5x, /20210108_dw-behavior-collection/hive_structure.jpg 2x" sizes=auto alt=/20210108_dw-behavior-collection/hive_structure.jpg></a><figcaption class=image-caption>hive_structure</figcaption></figure></p></blockquote><blockquote><p>内部表和外部表区别：</p><ol><li>内部表删除数据：元数据、原始数据 删掉</li><li>外表删数据：元数据删掉，原始数据保留</li><li>只有自己临时使用表，创建内部表。绝大部分场景都是外部表</li></ol></blockquote><blockquote><p>4个by：</p><p>order by：全局排序 （只有一个reduce task，数据倾斜，资源分配不足）不使用</p><p>sort by：局部排序，只保证每个 reducer task 输出有序</p><p>distribute by：分桶，取余分组，没有排序</p><p>cluster by： distribute by + sort by</p></blockquote><blockquote><p>自定义函数：</p><ol><li>自定义udf函数步骤： 1进1出，一行，定义类 继承udf，重写 evaluate 方法</li><li>自定义udtf函数步骤：多进多出，继承 udtf，重写三个方法（初始化（定义名称、校验返回值类型）、close、process）。打包+上传hdfs+在hive客户端创建</li></ol></blockquote><blockquote><p>窗口函数：rank、over、topn</p></blockquote><blockquote><p>优化：</p><ol><li>行列过滤：join -> where => where -> join</li><li>分区</li><li>小文件：combineHiveInputformat 或者 JVM重用 或者 merge</li><li>压缩</li></ol></blockquote><h2 id=数据仓库-1 class=headerLink><a href=#%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93-1 class=header-mark></a>数据仓库</h2><h3 id=数据分层 class=headerLink><a href=#%e6%95%b0%e6%8d%ae%e5%88%86%e5%b1%82 class=header-mark></a>数据分层</h3><blockquote><ul><li>ODS（Operation Data Store）原始数据层：存放原始数据，起到备份的作用</li><li>DWD（Data Warehouse Detail）明细数据层：清洗，去空，去脏数据，维度退化</li><li>DWS（DW service）按天进行轻度汇总</li><li>DWT（DW Topic）按主题进行汇总</li><li>ADS（Application Data Store）为各种统计报表提供数据</li></ul></blockquote><h3 id=数仓建模 class=headerLink><a href=#%e6%95%b0%e4%bb%93%e5%bb%ba%e6%a8%a1 class=header-mark></a>数仓建模</h3><blockquote><p>ODS层：</p><ul><li>创建支持LZO压缩的表：减少存储空间，100g -> 10g - 5g(取决于文件格式，比如JSON的嵌套方式，CSV的列数量)</li><li>创建分区表：防止全表扫描（导数据：全量、增量、新增和变化）</li><li>保持数据原貌不做任何修改，起到备份数据的作用</li></ul></blockquote><blockquote><p>DWD层：🔶</p><ul><li>选择业务过程 -> 声明粒度 -> 确认维度 -> 确认事实</li><li>业务过程：哪些协议需要做处理</li><li>声明粒度：粒度可以是天、一人、区域</li><li>确认维度：时间维度、地区维度、用户维度</li><li>确认事实：业务中的度量值（次数、个数、件数、金额、可以进行累加）</li></ul></blockquote><blockquote><p>DWS层：</p><ul><li>对各个主题对象进行统计：天、月、年、地区、用户</li></ul></blockquote><blockquote><p>DWT层：</p><ul><li>统计累计行为：从开始到结束，总结表</li></ul></blockquote><h3 id=数据处理 class=headerLink><a href=#%e6%95%b0%e6%8d%ae%e5%a4%84%e7%90%86 class=header-mark></a>数据处理</h3><blockquote><p>数据处理大致分为两大类：</p><ul><li>OLTP（on-line transaction processing）联机事务处理</li><li>OLAP（on-line Analytical Processing）联机分析处理</li></ul></blockquote></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2021-01-08</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/datawarehouse/>DataWarehouse</a>,&nbsp;<a href=/tags/tuning/>Tuning</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/20201215_parquet-format/ class=prev rel=prev title="HDFS: Parquet Format"><i class="fas fa-angle-left fa-fw"></i>HDFS: Parquet Format</a>
<a href=/20210308_dw-flink/ class=next rel=next title="Data Warehouse: Real-Time, part Ⅰ">Data Warehouse: Real-Time, part Ⅰ<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=valine class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://valine.js.org/>Valine</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2018 - 2023</span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><div id=cookieconsent-container></div><div class=assets><link rel=stylesheet href=/lib/valine/valine.min.css><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:40},comment:{valine:{appId:"2jSYKh8PFUje3v7Ie3Nn5v1g-gzGzoHsz",appKey:"MyWn4P9G5N32q3oM5JDnlpdL",avatar:"retro",el:"#valine",emojiCDN:"https://cdn.jsdelivr.net/npm/emoji-datasource-google@5.0.1/img/google/64/",emojiMaps:{100:"1f4af.png",alien:"1f47d.png",anger:"1f4a2.png",angry:"1f620.png",anguished:"1f627.png",astonished:"1f632.png",black_heart:"1f5a4.png",blue_heart:"1f499.png",blush:"1f60a.png",bomb:"1f4a3.png",boom:"1f4a5.png",broken_heart:"1f494.png",brown_heart:"1f90e.png",clown_face:"1f921.png",cold_face:"1f976.png",cold_sweat:"1f630.png",confounded:"1f616.png",confused:"1f615.png",cry:"1f622.png",crying_cat_face:"1f63f.png",cupid:"1f498.png",dash:"1f4a8.png",disappointed:"1f61e.png",disappointed_relieved:"1f625.png",dizzy:"1f4ab.png",dizzy_face:"1f635.png",drooling_face:"1f924.png",exploding_head:"1f92f.png",expressionless:"1f611.png",face_vomiting:"1f92e.png",face_with_cowboy_hat:"1f920.png",face_with_hand_over_mouth:"1f92d.png",face_with_head_bandage:"1f915.png",face_with_monocle:"1f9d0.png",face_with_raised_eyebrow:"1f928.png",face_with_rolling_eyes:"1f644.png",face_with_symbols_on_mouth:"1f92c.png",face_with_thermometer:"1f912.png",fearful:"1f628.png",flushed:"1f633.png",frowning:"1f626.png",ghost:"1f47b.png",gift_heart:"1f49d.png",green_heart:"1f49a.png",grimacing:"1f62c.png",grin:"1f601.png",grinning:"1f600.png",hankey:"1f4a9.png",hear_no_evil:"1f649.png",heart:"2764-fe0f.png",heart_decoration:"1f49f.png",heart_eyes:"1f60d.png",heart_eyes_cat:"1f63b.png",heartbeat:"1f493.png",heartpulse:"1f497.png",heavy_heart_exclamation_mark_ornament:"2763-fe0f.png",hole:"1f573-fe0f.png",hot_face:"1f975.png",hugging_face:"1f917.png",hushed:"1f62f.png",imp:"1f47f.png",innocent:"1f607.png",japanese_goblin:"1f47a.png",japanese_ogre:"1f479.png",joy:"1f602.png",joy_cat:"1f639.png",kiss:"1f48b.png",kissing:"1f617.png",kissing_cat:"1f63d.png",kissing_closed_eyes:"1f61a.png",kissing_heart:"1f618.png",kissing_smiling_eyes:"1f619.png",laughing:"1f606.png",left_speech_bubble:"1f5e8-fe0f.png",love_letter:"1f48c.png",lying_face:"1f925.png",mask:"1f637.png",money_mouth_face:"1f911.png",nauseated_face:"1f922.png",nerd_face:"1f913.png",neutral_face:"1f610.png",no_mouth:"1f636.png",open_mouth:"1f62e.png",orange_heart:"1f9e1.png",partying_face:"1f973.png",pensive:"1f614.png",persevere:"1f623.png",pleading_face:"1f97a.png",pouting_cat:"1f63e.png",purple_heart:"1f49c.png",rage:"1f621.png",relaxed:"263a-fe0f.png",relieved:"1f60c.png",revolving_hearts:"1f49e.png",right_anger_bubble:"1f5ef-fe0f.png",robot_face:"1f916.png",rolling_on_the_floor_laughing:"1f923.png",scream:"1f631.png",scream_cat:"1f640.png",see_no_evil:"1f648.png",shushing_face:"1f92b.png",skull:"1f480.png",skull_and_crossbones:"2620-fe0f.png",sleeping:"1f634.png",sleepy:"1f62a.png",slightly_frowning_face:"1f641.png",slightly_smiling_face:"1f642.png",smile:"1f604.png",smile_cat:"1f638.png",smiley:"1f603.png",smiley_cat:"1f63a.png",smiling_face_with_3_hearts:"1f970.png",smiling_imp:"1f608.png",smirk:"1f60f.png",smirk_cat:"1f63c.png",sneezing_face:"1f927.png",sob:"1f62d.png",space_invader:"1f47e.png",sparkling_heart:"1f496.png",speak_no_evil:"1f64a.png",speech_balloon:"1f4ac.png","star-struck":"1f929.png",stuck_out_tongue:"1f61b.png",stuck_out_tongue_closed_eyes:"1f61d.png",stuck_out_tongue_winking_eye:"1f61c.png",sunglasses:"1f60e.png",sweat:"1f613.png",sweat_drops:"1f4a6.png",sweat_smile:"1f605.png",thinking_face:"1f914.png",thought_balloon:"1f4ad.png",tired_face:"1f62b.png",triumph:"1f624.png",two_hearts:"1f495.png",unamused:"1f612.png",upside_down_face:"1f643.png",weary:"1f629.png",white_frowning_face:"2639-fe0f.png",white_heart:"1f90d.png",wink:"1f609.png",woozy_face:"1f974.png",worried:"1f61f.png",yawning_face:"1f971.png",yellow_heart:"1f49b.png",yum:"1f60b.png",zany_face:"1f92a.png",zipper_mouth_face:"1f910.png",zzz:"1f4a4.png"},enableQQ:!1,highlight:!0,lang:"en",meta:["nick","mail"],pageSize:10,placeholder:"Your comment ...",recordIP:!0,visitor:!0}},cookieconsent:{content:{dismiss:"Got it!",link:"Learn more",message:"This website uses Cookies to improve your experience."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},lightGallery:{actualSize:!1,exThumbImage:"data-thumbnail",hideBarsDelay:2e3,selector:".lightgallery",speed:400,thumbContHeight:80,thumbWidth:80,thumbnail:!0},search:{algoliaAppID:"BADKNNRXHD",algoliaIndex:"index",algoliaSearchKey:"7a8c2923330a44bdd9985698e3f28e0c",highlightTag:"em",maxResultLength:10,noResultsFound:"No results found",snippetLength:50,type:"algolia"},table:{sort:!0}}</script><script type=text/javascript src=/lib/valine/Valine.min.js defer></script><script type=text/javascript src=/js/valine.min.js defer></script><script type=text/javascript src=/lib/tablesort/tablesort.min.js></script><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/cookieconsent/cookieconsent.min.js defer></script><script type=text/javascript src=/js/cookieconsent.min.js defer></script><script type=text/javascript src=/js/theme.min.js defer></script></div></body></html>